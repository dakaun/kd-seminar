{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nils\\\\Documents\\\\KIT-TVWL\\\\Master\\\\SS 18\\\\KD Seminar\\\\Git\\\\mlp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "wd = os.getcwd()\n",
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>articleCount</th>\n",
       "      <th>avgSentiment</th>\n",
       "      <th>stdSentiment</th>\n",
       "      <th>25quantileSentiment</th>\n",
       "      <th>50quantileSentiment</th>\n",
       "      <th>75quantileSentiment</th>\n",
       "      <th>maxSentiment</th>\n",
       "      <th>minSentiment</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>nbOfDuplicates</th>\n",
       "      <th>Previous_Day_Return</th>\n",
       "      <th>Next_Day_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Allianz</td>\n",
       "      <td>8</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.165044</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>-0.21495</td>\n",
       "      <td>0.38493</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.002873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>49</td>\n",
       "      <td>0.227029</td>\n",
       "      <td>0.139967</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.226060</td>\n",
       "      <td>0.307010</td>\n",
       "      <td>-0.07551</td>\n",
       "      <td>0.59613</td>\n",
       "      <td>25701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>-0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Total</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.028149</td>\n",
       "      <td>0.150502</td>\n",
       "      <td>-0.099015</td>\n",
       "      <td>-0.033090</td>\n",
       "      <td>0.080382</td>\n",
       "      <td>-0.37195</td>\n",
       "      <td>0.21213</td>\n",
       "      <td>41980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>50</td>\n",
       "      <td>0.051116</td>\n",
       "      <td>0.161383</td>\n",
       "      <td>-0.076331</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.167947</td>\n",
       "      <td>-0.34760</td>\n",
       "      <td>0.35625</td>\n",
       "      <td>4259</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.003025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Google</td>\n",
       "      <td>50</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>0.121643</td>\n",
       "      <td>0.256883</td>\n",
       "      <td>-0.27442</td>\n",
       "      <td>0.56105</td>\n",
       "      <td>9678</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.001416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp       ID  articleCount  avgSentiment  stdSentiment  \\\n",
       "0 2016-12-27  Allianz             8      0.089320      0.165044   \n",
       "1 2016-12-27    Bayer            49      0.227029      0.139967   \n",
       "2 2016-12-27    Total            16     -0.028149      0.150502   \n",
       "3 2016-12-27   Airbus            50      0.051116      0.161383   \n",
       "4 2016-12-27   Google            50      0.128637      0.197749   \n",
       "\n",
       "   25quantileSentiment  50quantileSentiment  75quantileSentiment  \\\n",
       "0             0.031465             0.120620             0.120620   \n",
       "1             0.132600             0.226060             0.307010   \n",
       "2            -0.099015            -0.033090             0.080382   \n",
       "3            -0.076331             0.059425             0.167947   \n",
       "4             0.003755             0.121643             0.256883   \n",
       "\n",
       "   maxSentiment  minSentiment  socialScore  nbOfDuplicates  \\\n",
       "0      -0.21495       0.38493            0               4   \n",
       "1      -0.07551       0.59613        25701               5   \n",
       "2      -0.37195       0.21213        41980               1   \n",
       "3      -0.34760       0.35625         4259               9   \n",
       "4      -0.27442       0.56105         9678               6   \n",
       "\n",
       "   Previous_Day_Return  Next_Day_Return  \n",
       "0            -0.000637        -0.002873  \n",
       "1             0.002231        -0.000304  \n",
       "2             0.000000        -0.013899  \n",
       "3            -0.001271        -0.003025  \n",
       "4             0.003866        -0.001416  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../final_data/complete_data.csv\")\n",
    "df.Timestamp = pd.to_datetime(df.Timestamp)\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For now, drop every Column related to IBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>articleCount</th>\n",
       "      <th>avgSentiment</th>\n",
       "      <th>stdSentiment</th>\n",
       "      <th>25quantileSentiment</th>\n",
       "      <th>50quantileSentiment</th>\n",
       "      <th>75quantileSentiment</th>\n",
       "      <th>maxSentiment</th>\n",
       "      <th>minSentiment</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>nbOfDuplicates</th>\n",
       "      <th>Previous_Day_Return</th>\n",
       "      <th>Next_Day_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Allianz</td>\n",
       "      <td>8</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.165044</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>-0.21495</td>\n",
       "      <td>0.38493</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.002873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>49</td>\n",
       "      <td>0.227029</td>\n",
       "      <td>0.139967</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.226060</td>\n",
       "      <td>0.307010</td>\n",
       "      <td>-0.07551</td>\n",
       "      <td>0.59613</td>\n",
       "      <td>25701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>-0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Total</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.028149</td>\n",
       "      <td>0.150502</td>\n",
       "      <td>-0.099015</td>\n",
       "      <td>-0.033090</td>\n",
       "      <td>0.080382</td>\n",
       "      <td>-0.37195</td>\n",
       "      <td>0.21213</td>\n",
       "      <td>41980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>50</td>\n",
       "      <td>0.051116</td>\n",
       "      <td>0.161383</td>\n",
       "      <td>-0.076331</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.167947</td>\n",
       "      <td>-0.34760</td>\n",
       "      <td>0.35625</td>\n",
       "      <td>4259</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.003025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Google</td>\n",
       "      <td>50</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>0.121643</td>\n",
       "      <td>0.256883</td>\n",
       "      <td>-0.27442</td>\n",
       "      <td>0.56105</td>\n",
       "      <td>9678</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.001416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp       ID  articleCount  avgSentiment  stdSentiment  \\\n",
       "0 2016-12-27  Allianz             8      0.089320      0.165044   \n",
       "1 2016-12-27    Bayer            49      0.227029      0.139967   \n",
       "2 2016-12-27    Total            16     -0.028149      0.150502   \n",
       "3 2016-12-27   Airbus            50      0.051116      0.161383   \n",
       "4 2016-12-27   Google            50      0.128637      0.197749   \n",
       "\n",
       "   25quantileSentiment  50quantileSentiment  75quantileSentiment  \\\n",
       "0             0.031465             0.120620             0.120620   \n",
       "1             0.132600             0.226060             0.307010   \n",
       "2            -0.099015            -0.033090             0.080382   \n",
       "3            -0.076331             0.059425             0.167947   \n",
       "4             0.003755             0.121643             0.256883   \n",
       "\n",
       "   maxSentiment  minSentiment  socialScore  nbOfDuplicates  \\\n",
       "0      -0.21495       0.38493            0               4   \n",
       "1      -0.07551       0.59613        25701               5   \n",
       "2      -0.37195       0.21213        41980               1   \n",
       "3      -0.34760       0.35625         4259               9   \n",
       "4      -0.27442       0.56105         9678               6   \n",
       "\n",
       "   Previous_Day_Return  Next_Day_Return  \n",
       "0            -0.000637        -0.002873  \n",
       "1             0.002231        -0.000304  \n",
       "2             0.000000        -0.013899  \n",
       "3            -0.001271        -0.003025  \n",
       "4             0.003866        -0.001416  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=1, how=\"all\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>articleCount</th>\n",
       "      <th>avgSentiment</th>\n",
       "      <th>stdSentiment</th>\n",
       "      <th>25quantileSentiment</th>\n",
       "      <th>50quantileSentiment</th>\n",
       "      <th>75quantileSentiment</th>\n",
       "      <th>maxSentiment</th>\n",
       "      <th>minSentiment</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>nbOfDuplicates</th>\n",
       "      <th>Previous_Day_Return</th>\n",
       "      <th>Next_Day_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>Telefonica</td>\n",
       "      <td>17</td>\n",
       "      <td>0.218136</td>\n",
       "      <td>0.198920</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.176340</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>BASF</td>\n",
       "      <td>50</td>\n",
       "      <td>0.241042</td>\n",
       "      <td>0.164649</td>\n",
       "      <td>0.18037</td>\n",
       "      <td>0.219495</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>-0.22564</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023093</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp          ID  articleCount  avgSentiment  stdSentiment  \\\n",
       "3584 2018-05-23  Telefonica            17      0.218136      0.198920   \n",
       "3585 2018-05-23        BASF            50      0.241042      0.164649   \n",
       "\n",
       "      25quantileSentiment  50quantileSentiment  75quantileSentiment  \\\n",
       "3584              0.07400             0.176340             0.287580   \n",
       "3585              0.18037             0.219495             0.323553   \n",
       "\n",
       "      maxSentiment  minSentiment  socialScore  nbOfDuplicates  \\\n",
       "3584       0.00266        0.6753           58               1   \n",
       "3585      -0.22564        0.6552            6               0   \n",
       "\n",
       "      Previous_Day_Return  Next_Day_Return  \n",
       "3584            -0.006431              NaN  \n",
       "3585            -0.023093              NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case financial Data is not complete, Drop days without financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how=\"any\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relabel Returns for Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>articleCount</th>\n",
       "      <th>avgSentiment</th>\n",
       "      <th>stdSentiment</th>\n",
       "      <th>25quantileSentiment</th>\n",
       "      <th>50quantileSentiment</th>\n",
       "      <th>75quantileSentiment</th>\n",
       "      <th>maxSentiment</th>\n",
       "      <th>minSentiment</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>nbOfDuplicates</th>\n",
       "      <th>Previous_Day_Return</th>\n",
       "      <th>Next_Day_Return</th>\n",
       "      <th>relabeled_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Allianz</td>\n",
       "      <td>8</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.165044</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>-0.21495</td>\n",
       "      <td>0.38493</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.002873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>49</td>\n",
       "      <td>0.227029</td>\n",
       "      <td>0.139967</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.226060</td>\n",
       "      <td>0.307010</td>\n",
       "      <td>-0.07551</td>\n",
       "      <td>0.59613</td>\n",
       "      <td>25701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Total</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.028149</td>\n",
       "      <td>0.150502</td>\n",
       "      <td>-0.099015</td>\n",
       "      <td>-0.033090</td>\n",
       "      <td>0.080382</td>\n",
       "      <td>-0.37195</td>\n",
       "      <td>0.21213</td>\n",
       "      <td>41980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Airbus</td>\n",
       "      <td>50</td>\n",
       "      <td>0.051116</td>\n",
       "      <td>0.161383</td>\n",
       "      <td>-0.076331</td>\n",
       "      <td>0.059425</td>\n",
       "      <td>0.167947</td>\n",
       "      <td>-0.34760</td>\n",
       "      <td>0.35625</td>\n",
       "      <td>4259</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.003025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>Google</td>\n",
       "      <td>50</td>\n",
       "      <td>0.128637</td>\n",
       "      <td>0.197749</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>0.121643</td>\n",
       "      <td>0.256883</td>\n",
       "      <td>-0.27442</td>\n",
       "      <td>0.56105</td>\n",
       "      <td>9678</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp       ID  articleCount  avgSentiment  stdSentiment  \\\n",
       "0 2016-12-27  Allianz             8      0.089320      0.165044   \n",
       "1 2016-12-27    Bayer            49      0.227029      0.139967   \n",
       "2 2016-12-27    Total            16     -0.028149      0.150502   \n",
       "3 2016-12-27   Airbus            50      0.051116      0.161383   \n",
       "4 2016-12-27   Google            50      0.128637      0.197749   \n",
       "\n",
       "   25quantileSentiment  50quantileSentiment  75quantileSentiment  \\\n",
       "0             0.031465             0.120620             0.120620   \n",
       "1             0.132600             0.226060             0.307010   \n",
       "2            -0.099015            -0.033090             0.080382   \n",
       "3            -0.076331             0.059425             0.167947   \n",
       "4             0.003755             0.121643             0.256883   \n",
       "\n",
       "   maxSentiment  minSentiment  socialScore  nbOfDuplicates  \\\n",
       "0      -0.21495       0.38493            0               4   \n",
       "1      -0.07551       0.59613        25701               5   \n",
       "2      -0.37195       0.21213        41980               1   \n",
       "3      -0.34760       0.35625         4259               9   \n",
       "4      -0.27442       0.56105         9678               6   \n",
       "\n",
       "   Previous_Day_Return  Next_Day_Return  relabeled_returns  \n",
       "0            -0.000637        -0.002873                  0  \n",
       "1             0.002231        -0.000304                  0  \n",
       "2             0.000000        -0.013899                  0  \n",
       "3            -0.001271        -0.003025                  0  \n",
       "4             0.003866        -0.001416                  0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"relabeled_returns\"] = df[\"Next_Day_Return\"].apply(lambda x: 0 if x < 0 else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days 325\n",
      "Features 11\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "no_companies = len(df[\"ID\"].unique())\n",
    "nr_days = int(df.shape[0] / no_companies)\n",
    "nr_feats = df.shape[1] -4 #(-3 wegen Timestamp, ID, Next_Day_Return, relabeled_returns)\n",
    "print(\"Days {}\".format(nr_days))\n",
    "print(\"Features {}\".format(nr_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-10    11\n",
       "2018-05-11    11\n",
       "Name: Timestamp, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Timestamp\"].value_counts()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>articleCount</th>\n",
       "      <th>avgSentiment</th>\n",
       "      <th>stdSentiment</th>\n",
       "      <th>25quantileSentiment</th>\n",
       "      <th>50quantileSentiment</th>\n",
       "      <th>75quantileSentiment</th>\n",
       "      <th>maxSentiment</th>\n",
       "      <th>minSentiment</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>nbOfDuplicates</th>\n",
       "      <th>Previous_Day_Return</th>\n",
       "      <th>Next_Day_Return</th>\n",
       "      <th>relabeled_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>Allianz</td>\n",
       "      <td>33</td>\n",
       "      <td>0.178543</td>\n",
       "      <td>0.157595</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.167788</td>\n",
       "      <td>0.253690</td>\n",
       "      <td>-0.075370</td>\n",
       "      <td>0.533870</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>50</td>\n",
       "      <td>0.238067</td>\n",
       "      <td>0.177588</td>\n",
       "      <td>0.116340</td>\n",
       "      <td>0.227980</td>\n",
       "      <td>0.341668</td>\n",
       "      <td>-0.103800</td>\n",
       "      <td>0.576811</td>\n",
       "      <td>11205</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.022140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>Telefonica</td>\n",
       "      <td>26</td>\n",
       "      <td>0.361680</td>\n",
       "      <td>0.096824</td>\n",
       "      <td>0.348430</td>\n",
       "      <td>0.412570</td>\n",
       "      <td>0.417530</td>\n",
       "      <td>0.051060</td>\n",
       "      <td>0.460550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>-0.006431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>Apple</td>\n",
       "      <td>50</td>\n",
       "      <td>0.160632</td>\n",
       "      <td>0.164589</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.218340</td>\n",
       "      <td>0.262358</td>\n",
       "      <td>-0.160460</td>\n",
       "      <td>0.501867</td>\n",
       "      <td>2103</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>Google</td>\n",
       "      <td>50</td>\n",
       "      <td>0.120498</td>\n",
       "      <td>0.196605</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.098670</td>\n",
       "      <td>0.236380</td>\n",
       "      <td>-0.325562</td>\n",
       "      <td>0.569340</td>\n",
       "      <td>3044</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>-0.011244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp          ID  articleCount  avgSentiment  stdSentiment  \\\n",
       "3570 2018-05-21     Allianz            33      0.178543      0.157595   \n",
       "3571 2018-05-21       Bayer            50      0.238067      0.177588   \n",
       "3572 2018-05-21  Telefonica            26      0.361680      0.096824   \n",
       "3573 2018-05-21       Apple            50      0.160632      0.164589   \n",
       "3574 2018-05-21      Google            50      0.120498      0.196605   \n",
       "\n",
       "      25quantileSentiment  50quantileSentiment  75quantileSentiment  \\\n",
       "3570             0.080300             0.167788             0.253690   \n",
       "3571             0.116340             0.227980             0.341668   \n",
       "3572             0.348430             0.412570             0.417530   \n",
       "3573             0.014390             0.218340             0.262358   \n",
       "3574             0.007847             0.098670             0.236380   \n",
       "\n",
       "      maxSentiment  minSentiment  socialScore  nbOfDuplicates  \\\n",
       "3570     -0.075370      0.533870           36               1   \n",
       "3571     -0.103800      0.576811        11205               7   \n",
       "3572      0.051060      0.460550            0               0   \n",
       "3573     -0.160460      0.501867         2103               4   \n",
       "3574     -0.325562      0.569340         3044               6   \n",
       "\n",
       "      Previous_Day_Return  Next_Day_Return  relabeled_returns  \n",
       "3570             0.000000        -0.020438                  0  \n",
       "3571             0.000000        -0.022140                  0  \n",
       "3572             0.003265        -0.006431                  0  \n",
       "3573             0.007060         0.006391                  1  \n",
       "3574             0.003055        -0.011244                  0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []#np.empty((int(nr_days) ,int(nr_feats * 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "labels_to_drop = [\"Timestamp\", \"ID\", \"Next_Day_Return\", \"relabeled_returns\"]\n",
    "for d in df[\"Timestamp\"].value_counts().index:\n",
    "    #print(d)\n",
    "    X.append(df[df[\"Timestamp\"] == d].drop(labels_to_drop, axis=1).values.reshape(1,nr_feats*no_companies))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 1, 121)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 121)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(int(nr_days), nr_feats*no_companies)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00287311, -0.00030394, -0.0138989 , ...,  0.00295892,\n",
       "        -0.00613328, -0.00427315],\n",
       "       [-0.00045465, -0.02329648, -0.0161786 , ..., -0.00479464,\n",
       "        -0.00101471,  0.02850906],\n",
       "       [ 0.0104713 ,  0.01420254,  0.02125741, ..., -0.01133799,\n",
       "         0.00547401,  0.0028452 ],\n",
       "       ...,\n",
       "       [-0.00156535,  0.        , -0.036134  , ...,  0.00202225,\n",
       "         0.00439561, -0.00071425],\n",
       "       [ 0.        ,  0.        ,  0.00705999, ...,  0.        ,\n",
       "         0.        ,  0.00326531],\n",
       "       [-0.01731168, -0.02035326,  0.03536714, ..., -0.00643089,\n",
       "         0.00639116, -0.0112441 ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df[[\"Timestamp\",\"Next_Day_Return\"]].copy()\n",
    "df_labels[\"Next_Day_Return\"].values.reshape(nr_days, no_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 1, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 1, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df[[\"Timestamp\",\"relabeled_returns\"]].copy()\n",
    "df_labels[\"relabeled_returns\"].values.reshape(nr_days, no_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28921d99d30>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD3VJREFUeJzt3X+s3XV9x/HnyzLINmXieiW1rWt1xQXMVvUGSYyGhU1+bBFc4tb+IcyZVA0kM+4PYfsDdCFxm8yEzNXU2QGJlLExQuPqtJJNskwGt9qVVkQuiHJp016HQRdMt5b3/rjfux7bc3tv7zm9R/g8H8nJ+Z739/P9ft+nafK638/3e85JVSFJatPLRt2AJGl0DAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSw84YdQPzWb58ea1Zs2bUbUjSi8auXbu+X1VjCxn7Ux8Ca9asYWJiYtRtSNKLRpLvLnSs00GS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhv3Uf1jsxWDN9f806hZeUp76xG+NugWpGZ4JSFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWrYvCGQZGuSQ0n29tT+Lsnu7vFUkt1dfU2SH/es+0zPNm9J8kiSySS3JsnpeUuSpIVayHcH3Qb8FXDHbKGqfm92OcktwHM945+oqvV99rMZ2AQ8COwALgO+eOotS5KGZd4zgap6AHi237rur/nfBbadbB9JVgBnV9XXqqqYCZSrTr1dSdIwDXpN4O3Awap6vKe2Nsk3knw1ydu72kpgqmfMVFfrK8mmJBNJJqanpwdsUZI0l0FDYCM/eRZwAHhtVb0J+AhwZ5KzgX7z/zXXTqtqS1WNV9X42NjYgC1Kkuay6N8TSHIG8DvAW2ZrVXUYONwt70ryBHAeM3/5r+rZfBWwf7HHliQNxyBnAr8BfKuq/n+aJ8lYkmXd8uuAdcCTVXUA+FGSi7rrCFcD9w1wbEnSECzkFtFtwNeANySZSvL+btUGTrwg/A5gT5L/BP4B+GBVzV5U/hDwN8Ak8ATeGSRJIzfvdFBVbZyj/vt9avcA98wxfgJ44yn2J0k6jfyNYeml7qZfGHUHLy03PTf/mBcRvzZCkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDFvJD81uTHEqyt6d2U5JnkuzuHlf0rLshyWSSx5Jc2lO/rKtNJrl++G9FknSqFnImcBtwWZ/6p6pqfffYAZDkfGADcEG3zV8nWZZkGfBp4HLgfGBjN1aSNELz/tB8VT2QZM0C93clcFdVHQa+k2QSuLBbN1lVTwIkuasb+81T7liSNDSDXBO4LsmebrronK62Eni6Z8xUV5ur3leSTUkmkkxMT08P0KIk6WQWGwKbgdcD64EDwC1dPX3G1knqfVXVlqoar6rxsbGxRbYoSZrPvNNB/VTVwdnlJJ8FvtC9nAJW9wxdBezvlueqS5JGZFFnAklW9Lx8NzB759B2YEOSs5KsBdYBDwEPA+uSrE1yJjMXj7cvvm1J0jDMeyaQZBtwMbA8yRRwI3BxkvXMTOk8BXwAoKr2JbmbmQu+R4Brq+pot5/rgC8By4CtVbVv6O9GknRKFnJ30MY+5c+dZPzNwM196juAHafUnSTptPITw5LUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGjZvCCTZmuRQkr09tb9I8q0ke5Lcm+SVXX1Nkh8n2d09PtOzzVuSPJJkMsmtSXJ63pIkaaEWciZwG3DZcbWdwBur6leBbwM39Kx7oqrWd48P9tQ3A5uAdd3j+H1KkpbYvCFQVQ8Azx5X+3JVHelePgisOtk+kqwAzq6qr1VVAXcAVy2uZUnSsAzjmsAfAF/seb02yTeSfDXJ27vaSmCqZ8xUV+sryaYkE0kmpqenh9CiJKmfgUIgyZ8AR4DPd6UDwGur6k3AR4A7k5wN9Jv/r7n2W1Vbqmq8qsbHxsYGaVGSdBJnLHbDJNcAvw1c0k3xUFWHgcPd8q4kTwDnMfOXf++U0Spg/2KPLUkajkWdCSS5DPgo8K6qer6nPpZkWbf8OmYuAD9ZVQeAHyW5qLsr6GrgvoG7lyQNZN4zgSTbgIuB5UmmgBuZuRvoLGBnd6fng92dQO8APp7kCHAU+GBVzV5U/hAzdxr9LDPXEHqvI0iSRmDeEKiqjX3Kn5tj7D3APXOsmwDeeErdSZJOKz8xLEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDVsQSGQZGuSQ0n29tRelWRnkse753O6epLcmmQyyZ4kb+7Z5ppu/ONJrhn+25EknYqFngncBlx2XO164P6qWgfc370GuBxY1z02AZthJjSAG4G3AhcCN84GhyRpNBYUAlX1APDsceUrgdu75duBq3rqd9SMB4FXJlkBXArsrKpnq+oHwE5ODBZJ0hIa5JrAuVV1AKB7fnVXXwk83TNuqqvNVT9Bkk1JJpJMTE9PD9CiJOlkTseF4fSp1UnqJxartlTVeFWNj42NDbU5SdIxg4TAwW6ah+75UFefAlb3jFsF7D9JXZI0IoOEwHZg9g6fa4D7eupXd3cJXQQ8100XfQl4Z5JzugvC7+xqkqQROWMhg5JsAy4GlieZYuYun08Adyd5P/A94D3d8B3AFcAk8DzwPoCqejbJnwIPd+M+XlXHX2yWJC2hBYVAVW2cY9UlfcYWcO0c+9kKbF1wd5Kk08pPDEtSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJatiiQyDJG5Ls7nn8MMmHk9yU5Jme+hU929yQZDLJY0kuHc5bkCQt1oJ+Y7ifqnoMWA+QZBnwDHAvMz8s/6mq+mTv+CTnAxuAC4DXAF9Jcl5VHV1sD5KkwQxrOugS4Imq+u5JxlwJ3FVVh6vqO8AkcOGQji9JWoRhhcAGYFvP6+uS7EmyNck5XW0l8HTPmKmuJkkakYFDIMmZwLuAv+9Km4HXMzNVdAC4ZXZon81rjn1uSjKRZGJ6enrQFiVJcxjGmcDlwNer6iBAVR2sqqNV9QLwWY5N+UwBq3u2WwXs77fDqtpSVeNVNT42NjaEFiVJ/QwjBDbSMxWUZEXPuncDe7vl7cCGJGclWQusAx4awvElSYu06LuDAJL8HPCbwAd6yn+eZD0zUz1Pza6rqn1J7ga+CRwBrvXOIEkarYFCoKqeB37xuNp7TzL+ZuDmQY4pSRoePzEsSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNWzgEEjyVJJHkuxOMtHVXpVkZ5LHu+dzunqS3JpkMsmeJG8e9PiSpMUb1pnAr1fV+qoa715fD9xfVeuA+7vXAJcD67rHJmDzkI4vSVqE0zUddCVwe7d8O3BVT/2OmvEg8MokK05TD5KkeQwjBAr4cpJdSTZ1tXOr6gBA9/zqrr4SeLpn26mu9hOSbEoykWRienp6CC1Kkvo5Ywj7eFtV7U/yamBnkm+dZGz61OqEQtUWYAvA+Pj4CeslScMx8JlAVe3vng8B9wIXAgdnp3m650Pd8Clgdc/mq4D9g/YgSVqcgUIgyc8necXsMvBOYC+wHbimG3YNcF+3vB24urtL6CLgudlpI0nS0ht0Ouhc4N4ks/u6s6r+OcnDwN1J3g98D3hPN34HcAUwCTwPvG/A40uSBjBQCFTVk8Cv9an/F3BJn3oB1w5yTEnS8PiJYUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhiw6BJKuT/EuSR5PsS/KHXf2mJM8k2d09rujZ5oYkk0keS3LpMN6AJGnxBvmh+SPAH1XV15O8AtiVZGe37lNV9cnewUnOBzYAFwCvAb6S5LyqOjpAD5KkASz6TKCqDlTV17vlHwGPAitPssmVwF1VdbiqvgNMAhcu9viSpMEN5ZpAkjXAm4D/6ErXJdmTZGuSc7raSuDpns2mmCM0kmxKMpFkYnp6ehgtSpL6GDgEkrwcuAf4cFX9ENgMvB5YDxwAbpkd2mfz6rfPqtpSVeNVNT42NjZoi5KkOQwUAkl+hpkA+HxV/SNAVR2sqqNV9QLwWY5N+UwBq3s2XwXsH+T4kqTBDHJ3UIDPAY9W1V/21Ff0DHs3sLdb3g5sSHJWkrXAOuChxR5fkjS4Qe4OehvwXuCRJLu72h8DG5OsZ2aq5yngAwBVtS/J3cA3mbmz6FrvDJKk0Vp0CFTVv9F/nn/HSba5Gbh5sceUJA2XnxiWpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktSwJQ+BJJcleSzJZJLrl/r4kqRjljQEkiwDPg1cDpzPzI/Sn7+UPUiSjlnqM4ELgcmqerKq/ge4C7hyiXuQJHXOWOLjrQSe7nk9Bbz1+EFJNgGbupf/neSxJeitBcuB74+6ifnkz0bdgUbkRfH/k49l1B0sxC8tdOBSh0C/f706oVC1Bdhy+ttpS5KJqhofdR9SP/7/HI2lng6aAlb3vF4F7F/iHiRJnaUOgYeBdUnWJjkT2ABsX+IeJEmdJZ0OqqojSa4DvgQsA7ZW1b6l7KFxTrHpp5n/P0cgVSdMyUuSGuEnhiWpYYaAJDXMEJCkhi315wQkiSS/wsy3Baxk5rNC+4HtVfXoSBtrkGcCkpZUko8y85UxAR5i5tbxANv8Usml591BDUryvqr621H3oTYl+TZwQVX973H1M4F9VbVuNJ21yTOBNn1s1A2oaS8Ar+lTX9Gt0xLymsBLVJI9c60Czl3KXqTjfBi4P8njHPtCydcCvwxcN7KuGuV00EtUkoPApcAPjl8F/HtV9ftLTFoSSV7GzFfLr2Tm/+QU8HBVHR1pYw3yTOCl6wvAy6tq9/Erkvzr0rcjHVNVLwAPjroPeSYgSU3zwrAkNcwQkKSGGQKS1DBDQJIa9n80F+A80q65GwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_labels[\"relabeled_returns\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anteil positiver Returns: 52.48% - Anteil negativer Returns: 47.52%\n"
     ]
    }
   ],
   "source": [
    "rate_pos_returns = df_labels[\"relabeled_returns\"].value_counts()[1] / df_labels.shape[0] * 100\n",
    "rate_neg_returns = df_labels[\"relabeled_returns\"].value_counts()[0] / df_labels.shape[0] * 100\n",
    "\n",
    "print(\"Anteil positiver Returns: {}% - Anteil negativer Returns: {}%\".format(round(rate_pos_returns, 2), round(rate_neg_returns, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_labels_single = df_labels.groupby(\"Timestamp\").agg(\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_labels_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y = df_labels[\"Next_Day_Return\"].values.reshape(nr_days, 10)#df_labels_single.values\n",
    "Y = df_labels[\"relabeled_returns\"].values.reshape(nr_days, no_companies)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, RobustScaler\n",
    "scaler      = MinMaxScaler(feature_range=(0, 1))\n",
    "std_scaler  = StandardScaler()\n",
    "nrm_scaler  = Normalizer()\n",
    "rob_scaler  = RobustScaler()\n",
    "rescaled    = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LeakyReLU, PReLU\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.losses import binary_crossentropy\n",
    "#from keras.optimizers import SGD\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(rescaled, Y, test_size=0.3, random_state=212134)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 dims\n",
      "Building model...\n",
      "11 classes\n"
     ]
    }
   ],
   "source": [
    "dims = X.shape[1]\n",
    "print(dims, 'dims')\n",
    "print(\"Building model...\")\n",
    "\n",
    "nb_classes = Y.shape[1]\n",
    "print(nb_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 121)\n",
      "(227, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Dense(Y.shape[1], input_shape=(dims,), kernel_initializer='uniform', activation=\"relu\"))\n",
    "model.add(Dense(Y.shape[1]**2, kernel_initializer='uniform', activation=\"relu\"))\n",
    "model.add(Dense(Y.shape[1]**2, kernel_initializer='uniform', activation=\"relu\"))\n",
    "model.add(Dense(Y.shape[1], kernel_initializer='uniform', activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              metrics=['accuracy']) # Accuracy performance metric\n",
    "\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 epochs=100,\n",
    "                 batch_size=30,\n",
    "                 verbose=2,\n",
    "                 validation_data=(X_val, y_val))\n",
    "\n",
    "### PREDICTION ###\n",
    "y_pred = model.predict(X_val)\n",
    "y_head = np.round(y_pred, 0)\n",
    "\n",
    "### EVALUATE Classification - MODEL ###\n",
    "\n",
    "score = model.evaluate(X_val, y_val,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.3606109619140625, 0.13333334028720856]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tanh(x):\n",
    "    return (K.tanh((2/3)*x) * 1.5)#1.7159) #(2/3)\n",
    "\n",
    "def custom_tanh_output(x):\n",
    "    return (K.sigmoid( (0.75) * x )) +0.001# (2/3) + 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.RandomNormal at 0x28943f62dd8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomNormal(mean=0.0, stddev=0.05, seed=123345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(optimizer=\"sgd\", dropout=True, \n",
    "               dropout_param=0.37, first_last_hl_size=30, mid_hl_size=50, input_activation=\"softmax\", no_layers=5):\n",
    "    \n",
    "    model = Sequential()\n",
    "    #Input Layer\n",
    "    model.add(Dense(nb_classes, input_shape=(dims,), activation=custom_tanh))#, use_bias=True\n",
    "                   #kernel_initializer=\"random_uniform\")) #input_activation\n",
    "    \n",
    "    #Hidden Layers\n",
    "    model.add(Dense(100, #kernel_initializer=\"random_normal\", #RandomNormal(mean=0.0, stddev=1/np.sqrt(dims*first_last_hl_size), seed=123345)\n",
    "                    activation=\"relu\"))#, use_bias=True)) \"relu\" , use_bias=True\n",
    "    #model.add(LeakyReLU(alpha=.001))\n",
    "    #model.add(PReLU())\n",
    "    if dropout:\n",
    "        model.add(Dropout(dropout_param))\n",
    "    i = 0\n",
    "    while i < no_layers:\n",
    "        model.add(Dense(mid_hl_size, activation=\"relu\"))#, use_bias=True))\n",
    "        #model.add(PReLU())\n",
    "        #model.add(LeakyReLU(alpha=.001))\n",
    "        if dropout:\n",
    "            model.add(Dropout(dropout_param))\n",
    "        i = i+1\n",
    "            \n",
    "    model.add(Dense(first_last_hl_size, activation=\"relu\"))#, use_bias=True))\n",
    "\n",
    "    #Output Layer\n",
    "    model.add(Dense(nb_classes, activation=custom_tanh_output)) \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1s - loss: 0.6940 - acc: 0.4909\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5309\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5006\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5285\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5273\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5236\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5285\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5261\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5236\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5103\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5067\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5297\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5333\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5370\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5321\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5055\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6907 - acc: 0.5455\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5139\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5127\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5333\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5273\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5006\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6933 - acc: 0.4982\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6944 - acc: 0.4958\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5321\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5285\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5248\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5188\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5491\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5394\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5091\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5236\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5188\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5188\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5067\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5115\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5042\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5176\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5139\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5176\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6923 - acc: 0.4994\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5139\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6927 - acc: 0.4945\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5139\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5115\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5139\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5164\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5152\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5067\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5394\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6939 - acc: 0.4982\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5006\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6947 - acc: 0.5018\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6934 - acc: 0.4994\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5152\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6961 - acc: 0.4848\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5055\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6938 - acc: 0.4994\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5176\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5200\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6940 - acc: 0.5188\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6944 - acc: 0.4982\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5333\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6946 - acc: 0.4982\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5224\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5261\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6942 - acc: 0.4933\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5055\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5115\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6953 - acc: 0.4848\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5055\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5285\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5079\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6919 - acc: 0.4982\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5176\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6947 - acc: 0.4885\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6944 - acc: 0.5103\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5091\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6940 - acc: 0.5127\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5224\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5309\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5200\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5200\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5491\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5224\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5370\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5103\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5285\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5055\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5152\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5164\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5152\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5152\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6936 - acc: 0.4824\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5236\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6943 - acc: 0.4873\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6936 - acc: 0.4933\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5152\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5176\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5503\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6906 - acc: 0.5502\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5335\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5383\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5179\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4988\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4988\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5299\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5191\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5395\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5179\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5383\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5239\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6923 - acc: 0.4964\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5443\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5215\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5096\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5478\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5407\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6907 - acc: 0.5395\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5275\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5323\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5335\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5383\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5239\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5431\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5203\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5538\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6896 - acc: 0.5371\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5287\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5383\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5299\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5646\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5407\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5096\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5395\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5455\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4988\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5347\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5622\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5359\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5443\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5311\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5311\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5203\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5431\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5323\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5443\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5478\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5263\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5538\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6949 - acc: 0.4909\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6938 - acc: 0.4958\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5127\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5006\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5564\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5297\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5321\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5224\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5358\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5224\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5261\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5212\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5333\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5042\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5382\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5297\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5079\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5370\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6896 - acc: 0.5297\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5091\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5236\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5503\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5442\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5309\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5442\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5370\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5248\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5358\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5236\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6885 - acc: 0.5285\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5285\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5382\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6907 - acc: 0.5321\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6875 - acc: 0.5467\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5358\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6885 - acc: 0.5394\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5285\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6881 - acc: 0.5479\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5248\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5394\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5406\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5236\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5394\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5321\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5382\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6885 - acc: 0.5394\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6868 - acc: 0.5333\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5442\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5236\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5527\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6937 - acc: 0.5079\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5127\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5103\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5212\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5030\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5442\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5418\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5285\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5261\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5345\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6882 - acc: 0.5467\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5576\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5491\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5285\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5248\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5127\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6882 - acc: 0.5297\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5467\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5152\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5285\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5612\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5370\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6896 - acc: 0.5430\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5430\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6867 - acc: 0.5491\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5394\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5273\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5382\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5636\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5236\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6885 - acc: 0.5455\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5503\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5612\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5564\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5333\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5382\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5333\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5430\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5491\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5406\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5479\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5370\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5248\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6874 - acc: 0.5442\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6868 - acc: 0.5491\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6870 - acc: 0.5382\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6873 - acc: 0.5576\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5503\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5430\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6875 - acc: 0.5503\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6929 - acc: 0.5167\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5395\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5455\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5467\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5443\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5407\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6869 - acc: 0.5407\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5634\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6850 - acc: 0.5431\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5431\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5395\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6864 - acc: 0.5622\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6865 - acc: 0.5526\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6873 - acc: 0.5658\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5610\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5658\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6868 - acc: 0.5658\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6852 - acc: 0.5550\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6851 - acc: 0.5610\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6858 - acc: 0.5574\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6856 - acc: 0.5610\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6873 - acc: 0.5682\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6829 - acc: 0.5658\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6865 - acc: 0.5598\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6827 - acc: 0.5634\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6808 - acc: 0.5778\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6844 - acc: 0.5694\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6801 - acc: 0.5718\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6812 - acc: 0.5634\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6838 - acc: 0.5610\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6797 - acc: 0.5610\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6809 - acc: 0.5682\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6778 - acc: 0.5586\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6814 - acc: 0.5574\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6806 - acc: 0.5670\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6829 - acc: 0.5610\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6778 - acc: 0.5538\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6836 - acc: 0.5562\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6831 - acc: 0.5622\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6826 - acc: 0.5670\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6776 - acc: 0.5742\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6843 - acc: 0.5682\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6782 - acc: 0.5694\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6777 - acc: 0.5682\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6797 - acc: 0.5789\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6760 - acc: 0.5467\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6811 - acc: 0.5622\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6774 - acc: 0.5766\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6781 - acc: 0.5646\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6759 - acc: 0.5610\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6950 - acc: 0.4970\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5103\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5188\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4933\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5006\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5321\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5236\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6951 - acc: 0.4873\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5358\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6957 - acc: 0.4739\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6952 - acc: 0.4836\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5321\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5067\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6933 - acc: 0.4848\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4970\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5285\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5261\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5103\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5103\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5115\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6966 - acc: 0.4861\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6936 - acc: 0.4958\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6945 - acc: 0.5188\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5152\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6954 - acc: 0.5018\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5224\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5018\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6950 - acc: 0.5006\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5091\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5176\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5103\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5188\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5152\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5261\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5152\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6907 - acc: 0.5345\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5188\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6948 - acc: 0.4982\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6951 - acc: 0.4994\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5515\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5442\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5273\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5394\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6918 - acc: 0.4994\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5055\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5248\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6946 - acc: 0.4848\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5127\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5333\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6957 - acc: 0.4812\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6937 - acc: 0.5467\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6982 - acc: 0.5370\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5115\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5430\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6986 - acc: 0.5152\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.7055 - acc: 0.5103\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.7024 - acc: 0.4994\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6963 - acc: 0.5273\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6938 - acc: 0.5127\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6967 - acc: 0.5200\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5152\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6966 - acc: 0.5152\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5273\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6949 - acc: 0.4933\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5345\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6979 - acc: 0.5224\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6981 - acc: 0.5139\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.7012 - acc: 0.5079\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6983 - acc: 0.5006\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6956 - acc: 0.5103\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6955 - acc: 0.5103\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5236\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5236\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5139\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6957 - acc: 0.5091\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6945 - acc: 0.5236\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6993 - acc: 0.5261\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6976 - acc: 0.5042\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6959 - acc: 0.5188\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6944 - acc: 0.5139\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6969 - acc: 0.5200\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5236\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5358\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.7012 - acc: 0.4788\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6945 - acc: 0.4958\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5309\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5248\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5188\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6946 - acc: 0.5248\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5176\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6949 - acc: 0.5200\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6946 - acc: 0.5200\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5115\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5006\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6953 - acc: 0.5188\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5188\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5236\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6977 - acc: 0.5139\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6938 - acc: 0.5176\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5285\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6980 - acc: 0.4581\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6946 - acc: 0.4844\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6969 - acc: 0.4569\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6984 - acc: 0.4916\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6961 - acc: 0.4737\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6957 - acc: 0.4916\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6939 - acc: 0.4904\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6949 - acc: 0.5036\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6978 - acc: 0.4880\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6975 - acc: 0.4833\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6975 - acc: 0.4665\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6961 - acc: 0.5000\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6965 - acc: 0.4868\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6964 - acc: 0.4701\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6941 - acc: 0.4833\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6943 - acc: 0.5132\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6942 - acc: 0.4844\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6947 - acc: 0.4940\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4880\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5323\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6960 - acc: 0.4653\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6975 - acc: 0.4689\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4916\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6952 - acc: 0.5251\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6959 - acc: 0.5024\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6956 - acc: 0.4833\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6921 - acc: 0.4988\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6957 - acc: 0.4581\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6954 - acc: 0.4892\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6941 - acc: 0.4677\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6953 - acc: 0.4868\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4988\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6971 - acc: 0.5072\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6943 - acc: 0.5132\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6948 - acc: 0.5132\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6971 - acc: 0.4856\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6939 - acc: 0.4904\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4892\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5191\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6952 - acc: 0.4892\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5012\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6937 - acc: 0.4809\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6948 - acc: 0.5072\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6951 - acc: 0.5024\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6948 - acc: 0.4940\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5144\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6945 - acc: 0.5060\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6935 - acc: 0.4952\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5060\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6942 - acc: 0.4880\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6984 - acc: 0.5091\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6952 - acc: 0.5200\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5067\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6940 - acc: 0.5055\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6945 - acc: 0.5006\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5115\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5055\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5273\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4970\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5394\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5224\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5212\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5261\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5479\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5176\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6896 - acc: 0.5370\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5309\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5030\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5321\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5297\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5358\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5297\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5467\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5333\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5079\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5358\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5527\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5273\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6894 - acc: 0.5309\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5152\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5309\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5285\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6872 - acc: 0.5455\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5358\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5309\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5333\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6870 - acc: 0.5394\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5345\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5467\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5309\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5370\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5236\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5467\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5358\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5370\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6857 - acc: 0.5491\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5430\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6894 - acc: 0.5370\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5333\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5224\n",
      "Epoch 1/50\n",
      " - 6s - loss: 0.7007 - acc: 0.5030\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6965 - acc: 0.4982\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6938 - acc: 0.5018\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5018\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6957 - acc: 0.4897\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5127\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5030\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5248\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5079\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5261\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5006\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5176\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6933 - acc: 0.4897\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5479\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5103\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5248\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5491\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5503\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5200\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5382\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5248\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5370\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5212\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5309\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5236\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5552\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5200\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5358\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6877 - acc: 0.5479\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5273\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6882 - acc: 0.5309\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5503\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5248\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5358\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6860 - acc: 0.5479\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5382\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5479\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5612\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6861 - acc: 0.5442\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6881 - acc: 0.5455\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5358\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6860 - acc: 0.5455\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5406\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6854 - acc: 0.5394\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6873 - acc: 0.5467\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5370\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6862 - acc: 0.5345\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6850 - acc: 0.5479\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6866 - acc: 0.5491\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6836 - acc: 0.5382\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6914 - acc: 0.5287\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5347\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5275\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5395\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5598\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5407\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5490\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6881 - acc: 0.5682\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6844 - acc: 0.5562\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5670\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6836 - acc: 0.5490\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6833 - acc: 0.5526\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6864 - acc: 0.5754\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6814 - acc: 0.5670\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6850 - acc: 0.5502\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6837 - acc: 0.5598\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6848 - acc: 0.5801\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6826 - acc: 0.5622\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6851 - acc: 0.5670\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6865 - acc: 0.5610\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6840 - acc: 0.5586\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6814 - acc: 0.5754\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6823 - acc: 0.5813\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6822 - acc: 0.5706\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6842 - acc: 0.5754\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6818 - acc: 0.5706\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6852 - acc: 0.5610\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6810 - acc: 0.5694\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6802 - acc: 0.5622\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6747 - acc: 0.5694\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6821 - acc: 0.5778\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6767 - acc: 0.5658\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6832 - acc: 0.5598\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6830 - acc: 0.5586\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6817 - acc: 0.5754\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6782 - acc: 0.5706\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6755 - acc: 0.5718\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6786 - acc: 0.5742\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6791 - acc: 0.5706\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6755 - acc: 0.5718\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6748 - acc: 0.5514\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6797 - acc: 0.5610\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6716 - acc: 0.5778\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6758 - acc: 0.5502\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6751 - acc: 0.5730\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6706 - acc: 0.5706\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6746 - acc: 0.5646\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6687 - acc: 0.5754\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6693 - acc: 0.5706\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6795 - acc: 0.5766\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6950 - acc: 0.4812\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6987 - acc: 0.4642\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5164\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5115\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6956 - acc: 0.5067\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6952 - acc: 0.4958\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6959 - acc: 0.5018\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5285\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5103\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6954 - acc: 0.4945\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6984 - acc: 0.4897\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6946 - acc: 0.4873\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6975 - acc: 0.4921\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5164\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6974 - acc: 0.5079\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6962 - acc: 0.4982\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6944 - acc: 0.5067\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5248\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5236\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5030\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4897\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5042\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6966 - acc: 0.5091\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6942 - acc: 0.5018\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6951 - acc: 0.5176\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4994\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5103\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5333\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6976 - acc: 0.4921\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5285\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6941 - acc: 0.5030\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5079\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6952 - acc: 0.5030\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6962 - acc: 0.4921\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6950 - acc: 0.4994\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5103\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5273\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6967 - acc: 0.4836\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6967 - acc: 0.5006\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6937 - acc: 0.4800\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6954 - acc: 0.4788\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6971 - acc: 0.4945\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5139\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5103\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5285\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5309\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5539\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6939 - acc: 0.4982\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5236\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6944 - acc: 0.5091\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6962 - acc: 0.5103\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6969 - acc: 0.5224\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6997 - acc: 0.5018\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.7001 - acc: 0.4921\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6954 - acc: 0.4945\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.7032 - acc: 0.4691\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6984 - acc: 0.4945\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6984 - acc: 0.5042\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6967 - acc: 0.5152\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6979 - acc: 0.5176\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.7002 - acc: 0.4824\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.7004 - acc: 0.4958\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6986 - acc: 0.5091\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6964 - acc: 0.5055\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.7011 - acc: 0.5164\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6984 - acc: 0.4958\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5503\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6980 - acc: 0.4836\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6958 - acc: 0.5358\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.7003 - acc: 0.4921\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6974 - acc: 0.4970\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.7013 - acc: 0.4800\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6977 - acc: 0.4970\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6959 - acc: 0.4933\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6896 - acc: 0.5442\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6959 - acc: 0.5200\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6972 - acc: 0.5139\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6996 - acc: 0.4873\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6980 - acc: 0.5115\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6987 - acc: 0.5200\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6991 - acc: 0.5042\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5224\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6963 - acc: 0.5152\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6960 - acc: 0.4921\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6953 - acc: 0.4788\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5212\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6948 - acc: 0.5091\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6963 - acc: 0.5103\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6964 - acc: 0.5152\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5139\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6977 - acc: 0.4994\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5333\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6960 - acc: 0.5188\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5030\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6947 - acc: 0.5079\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6972 - acc: 0.5176\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.7006 - acc: 0.4800\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6944 - acc: 0.5285\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6979 - acc: 0.4909\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.7007 - acc: 0.4861\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.7000 - acc: 0.5132\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.7028 - acc: 0.4904\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.7043 - acc: 0.5060\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.7052 - acc: 0.4880\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6972 - acc: 0.5203\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6973 - acc: 0.5072\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6968 - acc: 0.5227\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.7001 - acc: 0.5000\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6972 - acc: 0.4976\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5443\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6949 - acc: 0.5072\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6940 - acc: 0.5191\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6946 - acc: 0.5179\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6870 - acc: 0.5311\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5311\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6964 - acc: 0.5179\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5108\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.7028 - acc: 0.4976\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6984 - acc: 0.5024\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6943 - acc: 0.5096\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6960 - acc: 0.5024\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6947 - acc: 0.5335\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5108\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6946 - acc: 0.5144\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5191\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6966 - acc: 0.5012\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6981 - acc: 0.4821\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6989 - acc: 0.5000\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6943 - acc: 0.5156\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6968 - acc: 0.5215\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6976 - acc: 0.5012\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6926 - acc: 0.4976\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5096\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6991 - acc: 0.5024\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5203\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.7046 - acc: 0.5108\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6975 - acc: 0.5108\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6831 - acc: 0.5371\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5251\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.7002 - acc: 0.4904\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6976 - acc: 0.5024\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6955 - acc: 0.5263\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5347\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6851 - acc: 0.5431\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6986 - acc: 0.4916\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5096\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5407\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6948 - acc: 0.5108\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6979 - acc: 0.5012\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6962 - acc: 0.5227\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.7020 - acc: 0.4848\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6952 - acc: 0.4982\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.7002 - acc: 0.4570\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6954 - acc: 0.4824\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6961 - acc: 0.4909\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6942 - acc: 0.5055\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6961 - acc: 0.4812\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6930 - acc: 0.4848\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6934 - acc: 0.4836\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4970\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5079\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5297\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5515\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5236\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5309\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5309\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5467\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5103\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5321\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5467\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5273\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5467\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5212\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5358\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5248\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5358\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5285\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5406\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5479\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5273\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5382\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5370\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5200\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5430\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5648\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5345\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5467\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6903 - acc: 0.5467\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5430\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6907 - acc: 0.5236\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5394\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5394\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5406\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5333\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6881 - acc: 0.5455\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5333\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5467\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5212\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6874 - acc: 0.5321\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5370\n",
      "Epoch 1/50\n",
      " - 2s - loss: 0.6963 - acc: 0.4897\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5188\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6975 - acc: 0.4776\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5248\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4921\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5152\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6939 - acc: 0.4958\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5188\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5345\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5224\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5103\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5200\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5224\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5394\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6937 - acc: 0.5345\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5030\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6909 - acc: 0.5285\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5345\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5309\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6911 - acc: 0.5176\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5285\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5600\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5491\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5515\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5297\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6887 - acc: 0.5394\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5297\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6894 - acc: 0.5382\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6868 - acc: 0.5588\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5515\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5321\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5370\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5382\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5370\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5345\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5358\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5430\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5455\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5539\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6872 - acc: 0.5333\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5455\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6867 - acc: 0.5309\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5430\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5212\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5564\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5358\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5479\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6868 - acc: 0.5406\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6872 - acc: 0.5394\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5333\n",
      "Epoch 1/50\n",
      " - 6s - loss: 0.6940 - acc: 0.5287\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5167\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6937 - acc: 0.5323\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5407\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6855 - acc: 0.5538\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5455\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6851 - acc: 0.5395\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5490\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5455\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6863 - acc: 0.5407\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6812 - acc: 0.5407\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6842 - acc: 0.5646\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6875 - acc: 0.5490\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6828 - acc: 0.5658\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6861 - acc: 0.5646\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6812 - acc: 0.5562\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6782 - acc: 0.5502\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6837 - acc: 0.5670\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5598\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6780 - acc: 0.5634\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5730\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6858 - acc: 0.5742\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6847 - acc: 0.5490\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6846 - acc: 0.5634\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5478\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5610\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6862 - acc: 0.5622\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6829 - acc: 0.5478\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6831 - acc: 0.5813\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6829 - acc: 0.5670\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6843 - acc: 0.5574\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6848 - acc: 0.5598\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6833 - acc: 0.5837\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6836 - acc: 0.5682\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6853 - acc: 0.5610\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6794 - acc: 0.5718\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6820 - acc: 0.5789\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5730\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6783 - acc: 0.5801\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6822 - acc: 0.5801\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6804 - acc: 0.5682\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6816 - acc: 0.5550\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6867 - acc: 0.5526\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6743 - acc: 0.5670\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6765 - acc: 0.5658\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6805 - acc: 0.5598\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6847 - acc: 0.5646\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6804 - acc: 0.5562\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6874 - acc: 0.5778\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6824 - acc: 0.5718\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6929 - acc: 0.4970\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5042\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4982\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6941 - acc: 0.4812\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5055\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6943 - acc: 0.4958\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6936 - acc: 0.4824\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6935 - acc: 0.4982\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6938 - acc: 0.4873\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6944 - acc: 0.4812\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5236\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6940 - acc: 0.4873\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5115\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6937 - acc: 0.4933\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5115\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5152\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5333\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5079\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5006\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5042\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5079\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6937 - acc: 0.5030\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5127\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5382\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5055\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5055\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6937 - acc: 0.4776\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5006\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6935 - acc: 0.4727\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5248\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5358\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5152\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5552\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5115\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5236\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5042\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5006\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5212\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5418\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5018\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6930 - acc: 0.4994\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5345\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5261\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5188\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5176\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5248\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5285\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5139\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5091\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5309\n",
      "Epoch 1/50\n",
      " - 3s - loss: 0.6929 - acc: 0.5030\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5030\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5273\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5176\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6937 - acc: 0.5127\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6936 - acc: 0.4958\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4933\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5273\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6934 - acc: 0.4982\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6931 - acc: 0.4994\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4921\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6934 - acc: 0.4994\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5261\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6937 - acc: 0.4691\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5079\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4945\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5127\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5079\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6935 - acc: 0.4812\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5479\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5103\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6930 - acc: 0.4933\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5200\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5164\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6939 - acc: 0.5115\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6933 - acc: 0.4982\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5200\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5006\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5285\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5248\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5139\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6933 - acc: 0.4921\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5103\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5176\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5224\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5055\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5345\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5067\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5115\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5273\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5042\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5515\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5042\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5200\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5115\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5200\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5188\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5164\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5236\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6937 - acc: 0.5103\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6928 - acc: 0.5108\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6935 - acc: 0.4988\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6929 - acc: 0.4976\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5311\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5395\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5538\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5287\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5263\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5263\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5203\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5120\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5431\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5431\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5371\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5347\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5359\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6924 - acc: 0.5610\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5407\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5490\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5239\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5263\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5443\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5586\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5562\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5634\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5574\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5407\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5419\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5371\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5478\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5431\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5562\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5634\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5443\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5682\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5550\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5622\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5538\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5598\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5574\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5622\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5514\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5538\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5598\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6919 - acc: 0.5538\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6915 - acc: 0.5718\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6914 - acc: 0.5718\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5562\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6910 - acc: 0.5610\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6934 - acc: 0.4897\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5285\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5164\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5248\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5406\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5309\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5406\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5261\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5370\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5006\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5358\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5370\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5333\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5212\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6905 - acc: 0.5236\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5430\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6906 - acc: 0.5164\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6885 - acc: 0.5418\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5394\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5358\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6890 - acc: 0.5430\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6894 - acc: 0.5564\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5273\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5309\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6875 - acc: 0.5467\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5236\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5406\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5394\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5430\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5261\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5273\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5491\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5224\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6900 - acc: 0.5224\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5358\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5309\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5442\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5539\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5248\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6893 - acc: 0.5394\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6877 - acc: 0.5418\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6864 - acc: 0.5333\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6872 - acc: 0.5491\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5430\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5164\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6878 - acc: 0.5527\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6877 - acc: 0.5394\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5358\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5418\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6888 - acc: 0.5321\n",
      "Epoch 1/50\n",
      " - 4s - loss: 0.6928 - acc: 0.5164\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6934 - acc: 0.4873\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5188\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6913 - acc: 0.5576\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6917 - acc: 0.5430\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6916 - acc: 0.5345\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5564\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6912 - acc: 0.5236\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6907 - acc: 0.5297\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5467\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5418\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5152\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5321\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5345\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6908 - acc: 0.5273\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6875 - acc: 0.5467\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6904 - acc: 0.5418\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6868 - acc: 0.5406\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6865 - acc: 0.5467\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6891 - acc: 0.5430\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5358\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6870 - acc: 0.5491\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5382\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6895 - acc: 0.5236\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6885 - acc: 0.5394\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5333\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5382\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6901 - acc: 0.5370\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6896 - acc: 0.5552\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5333\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6882 - acc: 0.5455\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6883 - acc: 0.5455\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5345\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6875 - acc: 0.5552\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6898 - acc: 0.5442\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6877 - acc: 0.5515\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5321\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6889 - acc: 0.5406\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6872 - acc: 0.5382\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6851 - acc: 0.5515\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6871 - acc: 0.5455\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6892 - acc: 0.5491\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5418\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6870 - acc: 0.5503\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6856 - acc: 0.5576\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6899 - acc: 0.5382\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6880 - acc: 0.5430\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5248\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6859 - acc: 0.5394\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6886 - acc: 0.5200\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6918 - acc: 0.5132\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6902 - acc: 0.5419\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6897 - acc: 0.5467\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6918 - acc: 0.5096\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6884 - acc: 0.5419\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6879 - acc: 0.5467\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6869 - acc: 0.5490\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6849 - acc: 0.5610\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6857 - acc: 0.5538\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6862 - acc: 0.5562\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6866 - acc: 0.5562\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6872 - acc: 0.5419\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6858 - acc: 0.5598\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6858 - acc: 0.5467\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6806 - acc: 0.5742\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6833 - acc: 0.5478\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6847 - acc: 0.5718\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6846 - acc: 0.5550\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6866 - acc: 0.5514\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6852 - acc: 0.5431\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6840 - acc: 0.5574\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6837 - acc: 0.5574\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6816 - acc: 0.5478\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6853 - acc: 0.5419\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6816 - acc: 0.5526\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6831 - acc: 0.5467\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6818 - acc: 0.5694\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6760 - acc: 0.5730\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6838 - acc: 0.5443\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6846 - acc: 0.5646\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6831 - acc: 0.5550\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6795 - acc: 0.5634\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6816 - acc: 0.5658\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6805 - acc: 0.5778\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6842 - acc: 0.5754\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6789 - acc: 0.5550\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6845 - acc: 0.5718\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6808 - acc: 0.5742\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6838 - acc: 0.5586\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6811 - acc: 0.5562\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6811 - acc: 0.5574\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6807 - acc: 0.5670\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6792 - acc: 0.5622\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6849 - acc: 0.5622\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6806 - acc: 0.5622\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6823 - acc: 0.5682\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6802 - acc: 0.5622\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6835 - acc: 0.5646\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6821 - acc: 0.5622\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6805 - acc: 0.5550\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.6939 - acc: 0.4907\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5350\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5068\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.6942 - acc: 0.4916\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6938 - acc: 0.5157\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6936 - acc: 0.5004\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5084\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.6929 - acc: 0.4988\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.6932 - acc: 0.4899\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5278\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6930 - acc: 0.4948\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5101\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.6930 - acc: 0.4996\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6937 - acc: 0.4932\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5157\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5028\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5076\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5101\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5157\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5084\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5310\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6935 - acc: 0.5044\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5093\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5157\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6928 - acc: 0.4996\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5189\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5318\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5117\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6927 - acc: 0.5076\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5149\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5028\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6934 - acc: 0.4883\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6932 - acc: 0.5237\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5197\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5221\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5173\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5181\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6936 - acc: 0.4867\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6920 - acc: 0.5278\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6931 - acc: 0.5173\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6923 - acc: 0.5165\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6933 - acc: 0.5245\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5109\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6930 - acc: 0.5044\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5286\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6922 - acc: 0.5326\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5125\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6925 - acc: 0.5221\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6929 - acc: 0.5060\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6926 - acc: 0.5173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001B3530FD908>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'epochs': [50], 'optimizer': ['sgd', 'RMSprop'], 'input_activation': ['softsign', 'tanh', 'softplus', 'softmax']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classifier = KerasClassifier(make_model,  verbose=2) #batch_size=10, epochs=100,\n",
    "\n",
    "batch_size = [10,12,14,30]#np.arange(55,105,10)\n",
    "epochs = [50]#np.arange(80,120,5)\n",
    "optimizer = [\"sgd\", \"RMSprop\"]#[\"sgd\", \"adam\", \"nadam\"]\n",
    "#dropout = [True, False]\n",
    "#dropout_param = np.linspace(0.29, 0.38, 10)\n",
    "input_activation=[\"softsign\", \"tanh\", \"softplus\", \"softmax\"]\n",
    "no_layers = np.arange(1,6)\n",
    "first_last_hl_size = np.arange(20,50,10)\n",
    "mid_hl_size = np.arange(30,150, 20)\n",
    "\n",
    "\n",
    "param_grid = dict(epochs=epochs, optimizer=optimizer, input_activation=input_activation)\n",
    "\n",
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid=param_grid)\n",
    "                         #scoring=[\"accuracy\"])\n",
    "                         #n_jobs=2)\n",
    "validator.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113 samples, validate on 29 samples\n",
      "Epoch 1/50\n",
      " - 26s - loss: 0.7030 - acc: 0.4755 - val_loss: 0.7037 - val_acc: 0.4890\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.7059 - acc: 0.4747 - val_loss: 0.7034 - val_acc: 0.4922\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.7001 - acc: 0.4972 - val_loss: 0.7032 - val_acc: 0.4953\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.7034 - acc: 0.4867 - val_loss: 0.7029 - val_acc: 0.4953\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.6974 - acc: 0.4932 - val_loss: 0.7027 - val_acc: 0.5016\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.6993 - acc: 0.4948 - val_loss: 0.7024 - val_acc: 0.5016\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.7018 - acc: 0.5012 - val_loss: 0.7022 - val_acc: 0.5016\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.7027 - acc: 0.4739 - val_loss: 0.7019 - val_acc: 0.4953\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.7012 - acc: 0.4747 - val_loss: 0.7017 - val_acc: 0.4922\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.7010 - acc: 0.4875 - val_loss: 0.7015 - val_acc: 0.4953\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.6978 - acc: 0.4899 - val_loss: 0.7013 - val_acc: 0.4953\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.6978 - acc: 0.5052 - val_loss: 0.7011 - val_acc: 0.4922\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.7012 - acc: 0.4851 - val_loss: 0.7009 - val_acc: 0.4984\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.6986 - acc: 0.4972 - val_loss: 0.7007 - val_acc: 0.4922\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.7008 - acc: 0.4803 - val_loss: 0.7005 - val_acc: 0.4859\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.6974 - acc: 0.4907 - val_loss: 0.7004 - val_acc: 0.4828\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.7009 - acc: 0.4779 - val_loss: 0.7002 - val_acc: 0.4796\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.6991 - acc: 0.4988 - val_loss: 0.7001 - val_acc: 0.4796\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.6982 - acc: 0.5036 - val_loss: 0.6999 - val_acc: 0.4828\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.7001 - acc: 0.4940 - val_loss: 0.6997 - val_acc: 0.4828\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.6964 - acc: 0.4996 - val_loss: 0.6995 - val_acc: 0.4796\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.6962 - acc: 0.5117 - val_loss: 0.6994 - val_acc: 0.4734\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.6961 - acc: 0.5101 - val_loss: 0.6993 - val_acc: 0.4796\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.6974 - acc: 0.4996 - val_loss: 0.6991 - val_acc: 0.4702\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.6963 - acc: 0.4940 - val_loss: 0.6989 - val_acc: 0.4702\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.6954 - acc: 0.5117 - val_loss: 0.6988 - val_acc: 0.4765\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.6954 - acc: 0.5141 - val_loss: 0.6987 - val_acc: 0.4796\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.6974 - acc: 0.4899 - val_loss: 0.6986 - val_acc: 0.4796\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.6975 - acc: 0.5004 - val_loss: 0.6985 - val_acc: 0.4796\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.7017 - acc: 0.4739 - val_loss: 0.6983 - val_acc: 0.4796\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.6962 - acc: 0.4972 - val_loss: 0.6982 - val_acc: 0.4859\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.6955 - acc: 0.5101 - val_loss: 0.6981 - val_acc: 0.4859\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.6995 - acc: 0.4779 - val_loss: 0.6979 - val_acc: 0.4859\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.6972 - acc: 0.5068 - val_loss: 0.6978 - val_acc: 0.4859\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.6921 - acc: 0.5101 - val_loss: 0.6977 - val_acc: 0.4828\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.6967 - acc: 0.5117 - val_loss: 0.6976 - val_acc: 0.4796\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.6979 - acc: 0.4875 - val_loss: 0.6975 - val_acc: 0.4796\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.6946 - acc: 0.4875 - val_loss: 0.6975 - val_acc: 0.4765\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.6977 - acc: 0.4916 - val_loss: 0.6974 - val_acc: 0.4796\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.6949 - acc: 0.5044 - val_loss: 0.6972 - val_acc: 0.4796\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.6943 - acc: 0.5052 - val_loss: 0.6972 - val_acc: 0.4796\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.6963 - acc: 0.5189 - val_loss: 0.6971 - val_acc: 0.4796\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.6928 - acc: 0.5181 - val_loss: 0.6969 - val_acc: 0.4828\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.6960 - acc: 0.5044 - val_loss: 0.6968 - val_acc: 0.4890\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.6969 - acc: 0.5012 - val_loss: 0.6967 - val_acc: 0.4828\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.6986 - acc: 0.4916 - val_loss: 0.6966 - val_acc: 0.4828\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.6934 - acc: 0.5133 - val_loss: 0.6965 - val_acc: 0.4828\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.6947 - acc: 0.5141 - val_loss: 0.6964 - val_acc: 0.4828\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.6942 - acc: 0.5020 - val_loss: 0.6964 - val_acc: 0.4859\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.6972 - acc: 0.4964 - val_loss: 0.6963 - val_acc: 0.4922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dbee036208>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.estimator.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters of the best model are: \n",
      "{'epochs': 50, 'input_activation': 'softmax', 'optimizer': 'sgd'}\n",
      "0.5156878454495321\n"
     ]
    }
   ],
   "source": [
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "print(validator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227 samples, validate on 98 samples\n",
      "Epoch 1/500\n",
      " - 13s - loss: 0.6941 - binary_accuracy: 0.5010 - val_loss: 0.6930 - val_binary_accuracy: 0.5306\n",
      "Epoch 2/500\n",
      " - 0s - loss: 0.6935 - binary_accuracy: 0.4986 - val_loss: 0.6930 - val_binary_accuracy: 0.4991\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.6926 - binary_accuracy: 0.5178 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      " - 0s - loss: 0.6932 - binary_accuracy: 0.5070 - val_loss: 0.6931 - val_binary_accuracy: 0.4944\n",
      "Epoch 5/500\n",
      " - 0s - loss: 0.6932 - binary_accuracy: 0.5118 - val_loss: 0.6931 - val_binary_accuracy: 0.4879\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.6921 - binary_accuracy: 0.5250 - val_loss: 0.6932 - val_binary_accuracy: 0.4879\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.6937 - binary_accuracy: 0.5026 - val_loss: 0.6933 - val_binary_accuracy: 0.4879\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.6931 - binary_accuracy: 0.4998 - val_loss: 0.6933 - val_binary_accuracy: 0.4879\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.6927 - binary_accuracy: 0.5062 - val_loss: 0.6933 - val_binary_accuracy: 0.4852\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.6928 - binary_accuracy: 0.5050 - val_loss: 0.6933 - val_binary_accuracy: 0.4879\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.6923 - binary_accuracy: 0.5170 - val_loss: 0.6933 - val_binary_accuracy: 0.4879\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.6924 - binary_accuracy: 0.5090 - val_loss: 0.6933 - val_binary_accuracy: 0.4879\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5158 - val_loss: 0.6933 - val_binary_accuracy: 0.4879\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.6925 - binary_accuracy: 0.5230 - val_loss: 0.6934 - val_binary_accuracy: 0.4620\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5102 - val_loss: 0.6935 - val_binary_accuracy: 0.4620\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.6910 - binary_accuracy: 0.5282 - val_loss: 0.6936 - val_binary_accuracy: 0.4620\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5150 - val_loss: 0.6936 - val_binary_accuracy: 0.4657\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.6925 - binary_accuracy: 0.5206 - val_loss: 0.6936 - val_binary_accuracy: 0.4675\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.6925 - binary_accuracy: 0.5078 - val_loss: 0.6935 - val_binary_accuracy: 0.4666\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.6929 - binary_accuracy: 0.5094 - val_loss: 0.6934 - val_binary_accuracy: 0.4740\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5174 - val_loss: 0.6933 - val_binary_accuracy: 0.4898\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.6927 - binary_accuracy: 0.5134 - val_loss: 0.6934 - val_binary_accuracy: 0.4926\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.6923 - binary_accuracy: 0.5262 - val_loss: 0.6935 - val_binary_accuracy: 0.4685\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.6913 - binary_accuracy: 0.5138 - val_loss: 0.6936 - val_binary_accuracy: 0.4675\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5158 - val_loss: 0.6937 - val_binary_accuracy: 0.4703\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.6928 - binary_accuracy: 0.5106 - val_loss: 0.6935 - val_binary_accuracy: 0.4685\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.6929 - binary_accuracy: 0.5094 - val_loss: 0.6934 - val_binary_accuracy: 0.4647\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5170 - val_loss: 0.6933 - val_binary_accuracy: 0.4722\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.6921 - binary_accuracy: 0.5250 - val_loss: 0.6933 - val_binary_accuracy: 0.4703\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.6929 - binary_accuracy: 0.5114 - val_loss: 0.6933 - val_binary_accuracy: 0.4731\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5186 - val_loss: 0.6933 - val_binary_accuracy: 0.4731\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5166 - val_loss: 0.6933 - val_binary_accuracy: 0.4731\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5270 - val_loss: 0.6934 - val_binary_accuracy: 0.4731\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.6923 - binary_accuracy: 0.5150 - val_loss: 0.6934 - val_binary_accuracy: 0.4731\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5270 - val_loss: 0.6934 - val_binary_accuracy: 0.4731\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.6922 - binary_accuracy: 0.5246 - val_loss: 0.6935 - val_binary_accuracy: 0.4731\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5210 - val_loss: 0.6935 - val_binary_accuracy: 0.4731\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.6914 - binary_accuracy: 0.5162 - val_loss: 0.6934 - val_binary_accuracy: 0.4731\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5174 - val_loss: 0.6934 - val_binary_accuracy: 0.4731\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.6921 - binary_accuracy: 0.5182 - val_loss: 0.6933 - val_binary_accuracy: 0.4731\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5150 - val_loss: 0.6932 - val_binary_accuracy: 0.4731\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5250 - val_loss: 0.6932 - val_binary_accuracy: 0.4731\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.6923 - binary_accuracy: 0.5174 - val_loss: 0.6932 - val_binary_accuracy: 0.4731\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.6922 - binary_accuracy: 0.5138 - val_loss: 0.6932 - val_binary_accuracy: 0.4731\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.6928 - binary_accuracy: 0.5122 - val_loss: 0.6933 - val_binary_accuracy: 0.4620\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5122 - val_loss: 0.6933 - val_binary_accuracy: 0.4620\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5226 - val_loss: 0.6933 - val_binary_accuracy: 0.4620\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5126 - val_loss: 0.6932 - val_binary_accuracy: 0.4629\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5206 - val_loss: 0.6933 - val_binary_accuracy: 0.4647\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5254 - val_loss: 0.6934 - val_binary_accuracy: 0.4620\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5130 - val_loss: 0.6935 - val_binary_accuracy: 0.4620\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5274 - val_loss: 0.6935 - val_binary_accuracy: 0.4638\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.6925 - binary_accuracy: 0.5142 - val_loss: 0.6935 - val_binary_accuracy: 0.4870\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5206 - val_loss: 0.6935 - val_binary_accuracy: 0.4657\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5154 - val_loss: 0.6936 - val_binary_accuracy: 0.4647\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5198 - val_loss: 0.6935 - val_binary_accuracy: 0.4620\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5202 - val_loss: 0.6935 - val_binary_accuracy: 0.4629\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.6922 - binary_accuracy: 0.5258 - val_loss: 0.6935 - val_binary_accuracy: 0.4620\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.6925 - binary_accuracy: 0.5170 - val_loss: 0.6936 - val_binary_accuracy: 0.4722\n",
      "Epoch 60/500\n",
      " - 0s - loss: 0.6915 - binary_accuracy: 0.5138 - val_loss: 0.6936 - val_binary_accuracy: 0.4777\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.6912 - binary_accuracy: 0.5226 - val_loss: 0.6935 - val_binary_accuracy: 0.4768\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5254 - val_loss: 0.6935 - val_binary_accuracy: 0.4750\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5118 - val_loss: 0.6935 - val_binary_accuracy: 0.4805\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5122 - val_loss: 0.6934 - val_binary_accuracy: 0.4731\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5190 - val_loss: 0.6934 - val_binary_accuracy: 0.4647\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.6923 - binary_accuracy: 0.5250 - val_loss: 0.6935 - val_binary_accuracy: 0.4777\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.6922 - binary_accuracy: 0.5102 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5170 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5162 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.6925 - binary_accuracy: 0.5150 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5158 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.6914 - binary_accuracy: 0.5274 - val_loss: 0.6935 - val_binary_accuracy: 0.4768\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5194 - val_loss: 0.6935 - val_binary_accuracy: 0.4768\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5294 - val_loss: 0.6936 - val_binary_accuracy: 0.4768\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.6915 - binary_accuracy: 0.5234 - val_loss: 0.6935 - val_binary_accuracy: 0.4768\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5146 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5210 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5106 - val_loss: 0.6934 - val_binary_accuracy: 0.4768\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.6910 - binary_accuracy: 0.5362 - val_loss: 0.6935 - val_binary_accuracy: 0.4833\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5110 - val_loss: 0.6936 - val_binary_accuracy: 0.4842\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.6924 - binary_accuracy: 0.5146 - val_loss: 0.6935 - val_binary_accuracy: 0.4675\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.6921 - binary_accuracy: 0.5090 - val_loss: 0.6934 - val_binary_accuracy: 0.4759\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.6921 - binary_accuracy: 0.5222 - val_loss: 0.6933 - val_binary_accuracy: 0.4777\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.6915 - binary_accuracy: 0.5162 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5210 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5198 - val_loss: 0.6932 - val_binary_accuracy: 0.4787\n",
      "Epoch 87/500\n",
      " - 0s - loss: 0.6912 - binary_accuracy: 0.5190 - val_loss: 0.6933 - val_binary_accuracy: 0.4842\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5166 - val_loss: 0.6932 - val_binary_accuracy: 0.4852\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5206 - val_loss: 0.6932 - val_binary_accuracy: 0.4768\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5178 - val_loss: 0.6931 - val_binary_accuracy: 0.4759\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5218 - val_loss: 0.6932 - val_binary_accuracy: 0.4768\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5158 - val_loss: 0.6932 - val_binary_accuracy: 0.4768\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5170 - val_loss: 0.6932 - val_binary_accuracy: 0.4768\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.6917 - binary_accuracy: 0.5150 - val_loss: 0.6932 - val_binary_accuracy: 0.4768\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.6910 - binary_accuracy: 0.5234 - val_loss: 0.6932 - val_binary_accuracy: 0.4722\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.6919 - binary_accuracy: 0.5162 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.6915 - binary_accuracy: 0.5234 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.6920 - binary_accuracy: 0.5146 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.6914 - binary_accuracy: 0.5250 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.6909 - binary_accuracy: 0.5178 - val_loss: 0.6933 - val_binary_accuracy: 0.4768\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.6914 - binary_accuracy: 0.5210 - val_loss: 0.6932 - val_binary_accuracy: 0.4731\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.6912 - binary_accuracy: 0.5174 - val_loss: 0.6932 - val_binary_accuracy: 0.4740\n",
      "Epoch 103/500\n",
      " - 0s - loss: 0.6912 - binary_accuracy: 0.5254 - val_loss: 0.6932 - val_binary_accuracy: 0.4796\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.6918 - binary_accuracy: 0.5250 - val_loss: 0.6932 - val_binary_accuracy: 0.4824\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.6909 - binary_accuracy: 0.5226 - val_loss: 0.6931 - val_binary_accuracy: 0.4833\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.6913 - binary_accuracy: 0.5242 - val_loss: 0.6932 - val_binary_accuracy: 0.4824\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.6912 - binary_accuracy: 0.5226 - val_loss: 0.6931 - val_binary_accuracy: 0.4852\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.6915 - binary_accuracy: 0.5278 - val_loss: 0.6931 - val_binary_accuracy: 0.4768\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.6916 - binary_accuracy: 0.5242 - val_loss: 0.6931 - val_binary_accuracy: 0.4768\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.6911 - binary_accuracy: 0.5222 - val_loss: 0.6931 - val_binary_accuracy: 0.4787\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.6907 - binary_accuracy: 0.5238 - val_loss: 0.6931 - val_binary_accuracy: 0.4814\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.6913 - binary_accuracy: 0.5242 - val_loss: 0.6930 - val_binary_accuracy: 0.4861\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.6913 - binary_accuracy: 0.5150 - val_loss: 0.6930 - val_binary_accuracy: 0.4842\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.6915 - binary_accuracy: 0.5170 - val_loss: 0.6931 - val_binary_accuracy: 0.4768\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.6904 - binary_accuracy: 0.5122 - val_loss: 0.6931 - val_binary_accuracy: 0.4787\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.6909 - binary_accuracy: 0.5234 - val_loss: 0.6930 - val_binary_accuracy: 0.4787\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.6905 - binary_accuracy: 0.5218 - val_loss: 0.6930 - val_binary_accuracy: 0.4824\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.6909 - binary_accuracy: 0.5174 - val_loss: 0.6929 - val_binary_accuracy: 0.4814\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.6902 - binary_accuracy: 0.5346 - val_loss: 0.6928 - val_binary_accuracy: 0.4796\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.6912 - binary_accuracy: 0.5190 - val_loss: 0.6928 - val_binary_accuracy: 0.4805\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.6895 - binary_accuracy: 0.5258 - val_loss: 0.6927 - val_binary_accuracy: 0.4842\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.6909 - binary_accuracy: 0.5238 - val_loss: 0.6928 - val_binary_accuracy: 0.4777\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.6898 - binary_accuracy: 0.5194 - val_loss: 0.6929 - val_binary_accuracy: 0.4768\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.6907 - binary_accuracy: 0.5062 - val_loss: 0.6928 - val_binary_accuracy: 0.4796\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.6906 - binary_accuracy: 0.5330 - val_loss: 0.6926 - val_binary_accuracy: 0.4824\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.6892 - binary_accuracy: 0.5302 - val_loss: 0.6924 - val_binary_accuracy: 0.4833\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.6898 - binary_accuracy: 0.5278 - val_loss: 0.6923 - val_binary_accuracy: 0.4879\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.6887 - binary_accuracy: 0.5306 - val_loss: 0.6924 - val_binary_accuracy: 0.4796\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.6876 - binary_accuracy: 0.5270 - val_loss: 0.6920 - val_binary_accuracy: 0.4879\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.6885 - binary_accuracy: 0.5310 - val_loss: 0.6922 - val_binary_accuracy: 0.4842\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.6889 - binary_accuracy: 0.5262 - val_loss: 0.6924 - val_binary_accuracy: 0.4935\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.6892 - binary_accuracy: 0.5310 - val_loss: 0.6922 - val_binary_accuracy: 0.4907\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.6893 - binary_accuracy: 0.5206 - val_loss: 0.6922 - val_binary_accuracy: 0.5028\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.6891 - binary_accuracy: 0.5294 - val_loss: 0.6923 - val_binary_accuracy: 0.4935\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.6860 - binary_accuracy: 0.5290 - val_loss: 0.6917 - val_binary_accuracy: 0.4898\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.6878 - binary_accuracy: 0.5366 - val_loss: 0.6915 - val_binary_accuracy: 0.5046\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.6874 - binary_accuracy: 0.5302 - val_loss: 0.6921 - val_binary_accuracy: 0.5028\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.6872 - binary_accuracy: 0.5302 - val_loss: 0.6915 - val_binary_accuracy: 0.5037\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.6857 - binary_accuracy: 0.5290 - val_loss: 0.6916 - val_binary_accuracy: 0.5074\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.6873 - binary_accuracy: 0.5262 - val_loss: 0.6924 - val_binary_accuracy: 0.5139\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.6853 - binary_accuracy: 0.5386 - val_loss: 0.6918 - val_binary_accuracy: 0.5093\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.6847 - binary_accuracy: 0.5318 - val_loss: 0.6916 - val_binary_accuracy: 0.5019\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.6844 - binary_accuracy: 0.5350 - val_loss: 0.6915 - val_binary_accuracy: 0.5028\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.6834 - binary_accuracy: 0.5467 - val_loss: 0.6917 - val_binary_accuracy: 0.5102\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.6831 - binary_accuracy: 0.5326 - val_loss: 0.6918 - val_binary_accuracy: 0.5148\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.6815 - binary_accuracy: 0.5306 - val_loss: 0.6917 - val_binary_accuracy: 0.5167\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.6816 - binary_accuracy: 0.5274 - val_loss: 0.6915 - val_binary_accuracy: 0.5380\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.6814 - binary_accuracy: 0.5427 - val_loss: 0.6913 - val_binary_accuracy: 0.5371\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.6778 - binary_accuracy: 0.5451 - val_loss: 0.6914 - val_binary_accuracy: 0.5353\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.6794 - binary_accuracy: 0.5439 - val_loss: 0.6917 - val_binary_accuracy: 0.5380\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.6788 - binary_accuracy: 0.5447 - val_loss: 0.6917 - val_binary_accuracy: 0.5362\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.6774 - binary_accuracy: 0.5423 - val_loss: 0.6915 - val_binary_accuracy: 0.5380\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.6823 - binary_accuracy: 0.5503 - val_loss: 0.6917 - val_binary_accuracy: 0.5343\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.6769 - binary_accuracy: 0.5483 - val_loss: 0.6914 - val_binary_accuracy: 0.5390\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.6755 - binary_accuracy: 0.5515 - val_loss: 0.6913 - val_binary_accuracy: 0.5399\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.6789 - binary_accuracy: 0.5487 - val_loss: 0.6916 - val_binary_accuracy: 0.5353\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.6772 - binary_accuracy: 0.5507 - val_loss: 0.6911 - val_binary_accuracy: 0.5417\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.6795 - binary_accuracy: 0.5386 - val_loss: 0.6919 - val_binary_accuracy: 0.5343\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.6737 - binary_accuracy: 0.5423 - val_loss: 0.6912 - val_binary_accuracy: 0.5408\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.6745 - binary_accuracy: 0.5475 - val_loss: 0.6916 - val_binary_accuracy: 0.5464\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.6755 - binary_accuracy: 0.5467 - val_loss: 0.6922 - val_binary_accuracy: 0.5353\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.6749 - binary_accuracy: 0.5547 - val_loss: 0.6918 - val_binary_accuracy: 0.5482\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.6798 - binary_accuracy: 0.5467 - val_loss: 0.6923 - val_binary_accuracy: 0.5343\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.6759 - binary_accuracy: 0.5507 - val_loss: 0.6917 - val_binary_accuracy: 0.5492\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.6773 - binary_accuracy: 0.5443 - val_loss: 0.6923 - val_binary_accuracy: 0.5353\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.6720 - binary_accuracy: 0.5515 - val_loss: 0.6918 - val_binary_accuracy: 0.5529\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.6778 - binary_accuracy: 0.5531 - val_loss: 0.6923 - val_binary_accuracy: 0.5408\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.6743 - binary_accuracy: 0.5483 - val_loss: 0.6923 - val_binary_accuracy: 0.5408\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.6713 - binary_accuracy: 0.5507 - val_loss: 0.6924 - val_binary_accuracy: 0.5473\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.6733 - binary_accuracy: 0.5443 - val_loss: 0.6927 - val_binary_accuracy: 0.5343\n",
      "Epoch 171/500\n",
      " - 0s - loss: 0.6692 - binary_accuracy: 0.5599 - val_loss: 0.6935 - val_binary_accuracy: 0.5390\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.6771 - binary_accuracy: 0.5551 - val_loss: 0.6929 - val_binary_accuracy: 0.5353\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.6768 - binary_accuracy: 0.5346 - val_loss: 0.6930 - val_binary_accuracy: 0.5325\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.6704 - binary_accuracy: 0.5611 - val_loss: 0.6926 - val_binary_accuracy: 0.5455\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.6693 - binary_accuracy: 0.5599 - val_loss: 0.6928 - val_binary_accuracy: 0.5492\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.6694 - binary_accuracy: 0.5483 - val_loss: 0.6932 - val_binary_accuracy: 0.5408\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.6727 - binary_accuracy: 0.5439 - val_loss: 0.6934 - val_binary_accuracy: 0.5380\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.6682 - binary_accuracy: 0.5515 - val_loss: 0.6931 - val_binary_accuracy: 0.5464\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.6734 - binary_accuracy: 0.5539 - val_loss: 0.6931 - val_binary_accuracy: 0.5445\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.6688 - binary_accuracy: 0.5543 - val_loss: 0.6933 - val_binary_accuracy: 0.5445\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.6761 - binary_accuracy: 0.5567 - val_loss: 0.6935 - val_binary_accuracy: 0.5464\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.6665 - binary_accuracy: 0.5499 - val_loss: 0.6936 - val_binary_accuracy: 0.5464\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.6690 - binary_accuracy: 0.5495 - val_loss: 0.6938 - val_binary_accuracy: 0.5399\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.6696 - binary_accuracy: 0.5459 - val_loss: 0.6940 - val_binary_accuracy: 0.5353\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.6651 - binary_accuracy: 0.5587 - val_loss: 0.6941 - val_binary_accuracy: 0.5315\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.6706 - binary_accuracy: 0.5451 - val_loss: 0.6945 - val_binary_accuracy: 0.5241\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.6665 - binary_accuracy: 0.5563 - val_loss: 0.6947 - val_binary_accuracy: 0.5278\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.6714 - binary_accuracy: 0.5607 - val_loss: 0.6951 - val_binary_accuracy: 0.5297\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.6705 - binary_accuracy: 0.5451 - val_loss: 0.6951 - val_binary_accuracy: 0.5278\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.6663 - binary_accuracy: 0.5515 - val_loss: 0.6952 - val_binary_accuracy: 0.5176\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.6651 - binary_accuracy: 0.5619 - val_loss: 0.6955 - val_binary_accuracy: 0.5204\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.6661 - binary_accuracy: 0.5631 - val_loss: 0.6963 - val_binary_accuracy: 0.5241\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.6668 - binary_accuracy: 0.5539 - val_loss: 0.6960 - val_binary_accuracy: 0.5148\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.6689 - binary_accuracy: 0.5627 - val_loss: 0.6956 - val_binary_accuracy: 0.5102\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.6649 - binary_accuracy: 0.5639 - val_loss: 0.6963 - val_binary_accuracy: 0.5167\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.6608 - binary_accuracy: 0.5631 - val_loss: 0.6961 - val_binary_accuracy: 0.5139\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.6668 - binary_accuracy: 0.5599 - val_loss: 0.6962 - val_binary_accuracy: 0.5148\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.6652 - binary_accuracy: 0.5743 - val_loss: 0.6961 - val_binary_accuracy: 0.5139\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.6698 - binary_accuracy: 0.5559 - val_loss: 0.6968 - val_binary_accuracy: 0.5195\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.6658 - binary_accuracy: 0.5699 - val_loss: 0.6969 - val_binary_accuracy: 0.5158\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.6607 - binary_accuracy: 0.5691 - val_loss: 0.6972 - val_binary_accuracy: 0.5065\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.6665 - binary_accuracy: 0.5823 - val_loss: 0.6975 - val_binary_accuracy: 0.5102\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.6627 - binary_accuracy: 0.5899 - val_loss: 0.6981 - val_binary_accuracy: 0.5056\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.6618 - binary_accuracy: 0.5743 - val_loss: 0.6980 - val_binary_accuracy: 0.5037\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.6670 - binary_accuracy: 0.5595 - val_loss: 0.6987 - val_binary_accuracy: 0.4917\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.6638 - binary_accuracy: 0.5811 - val_loss: 0.6986 - val_binary_accuracy: 0.4889\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.6597 - binary_accuracy: 0.5967 - val_loss: 0.6991 - val_binary_accuracy: 0.4852\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.6601 - binary_accuracy: 0.5875 - val_loss: 0.6995 - val_binary_accuracy: 0.4833\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.6620 - binary_accuracy: 0.5911 - val_loss: 0.6992 - val_binary_accuracy: 0.4824\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.6619 - binary_accuracy: 0.5843 - val_loss: 0.6992 - val_binary_accuracy: 0.4787\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.6569 - binary_accuracy: 0.5891 - val_loss: 0.6997 - val_binary_accuracy: 0.4879\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.6605 - binary_accuracy: 0.5831 - val_loss: 0.6995 - val_binary_accuracy: 0.4898\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.6636 - binary_accuracy: 0.5763 - val_loss: 0.6996 - val_binary_accuracy: 0.4842\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.6590 - binary_accuracy: 0.5835 - val_loss: 0.7003 - val_binary_accuracy: 0.4842\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.6595 - binary_accuracy: 0.5987 - val_loss: 0.7009 - val_binary_accuracy: 0.4889\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.6626 - binary_accuracy: 0.5839 - val_loss: 0.7010 - val_binary_accuracy: 0.4907\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.6590 - binary_accuracy: 0.5895 - val_loss: 0.7000 - val_binary_accuracy: 0.4870\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.6618 - binary_accuracy: 0.5795 - val_loss: 0.7003 - val_binary_accuracy: 0.4944\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.6560 - binary_accuracy: 0.5815 - val_loss: 0.7022 - val_binary_accuracy: 0.4898\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.6586 - binary_accuracy: 0.5859 - val_loss: 0.7014 - val_binary_accuracy: 0.4759\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.6608 - binary_accuracy: 0.5995 - val_loss: 0.7036 - val_binary_accuracy: 0.4852\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.6611 - binary_accuracy: 0.5871 - val_loss: 0.7034 - val_binary_accuracy: 0.4861\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.6542 - binary_accuracy: 0.5971 - val_loss: 0.7046 - val_binary_accuracy: 0.4879\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.6547 - binary_accuracy: 0.6015 - val_loss: 0.7049 - val_binary_accuracy: 0.4898\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.6574 - binary_accuracy: 0.5867 - val_loss: 0.7031 - val_binary_accuracy: 0.4898\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.6614 - binary_accuracy: 0.5891 - val_loss: 0.7035 - val_binary_accuracy: 0.4750\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.6553 - binary_accuracy: 0.5867 - val_loss: 0.7086 - val_binary_accuracy: 0.4907\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.6541 - binary_accuracy: 0.5939 - val_loss: 0.7044 - val_binary_accuracy: 0.4879\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.6597 - binary_accuracy: 0.5839 - val_loss: 0.7051 - val_binary_accuracy: 0.4861\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.6583 - binary_accuracy: 0.5999 - val_loss: 0.7049 - val_binary_accuracy: 0.4861\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.6528 - binary_accuracy: 0.5979 - val_loss: 0.7058 - val_binary_accuracy: 0.4833\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.6567 - binary_accuracy: 0.5995 - val_loss: 0.7076 - val_binary_accuracy: 0.4870\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.6561 - binary_accuracy: 0.5951 - val_loss: 0.7059 - val_binary_accuracy: 0.4768\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.6574 - binary_accuracy: 0.5811 - val_loss: 0.7079 - val_binary_accuracy: 0.4870\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.6589 - binary_accuracy: 0.5923 - val_loss: 0.7066 - val_binary_accuracy: 0.4926\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.6557 - binary_accuracy: 0.5903 - val_loss: 0.7065 - val_binary_accuracy: 0.4907\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.6514 - binary_accuracy: 0.5955 - val_loss: 0.7098 - val_binary_accuracy: 0.4805\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.6555 - binary_accuracy: 0.6091 - val_loss: 0.7072 - val_binary_accuracy: 0.4796\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.6524 - binary_accuracy: 0.6003 - val_loss: 0.7111 - val_binary_accuracy: 0.4926\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.6524 - binary_accuracy: 0.5907 - val_loss: 0.7124 - val_binary_accuracy: 0.4852\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.6577 - binary_accuracy: 0.5831 - val_loss: 0.7087 - val_binary_accuracy: 0.5009\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.6522 - binary_accuracy: 0.6003 - val_loss: 0.7100 - val_binary_accuracy: 0.4703\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.6559 - binary_accuracy: 0.5999 - val_loss: 0.7101 - val_binary_accuracy: 0.4759\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.6556 - binary_accuracy: 0.5903 - val_loss: 0.7090 - val_binary_accuracy: 0.4981\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.6568 - binary_accuracy: 0.5979 - val_loss: 0.7109 - val_binary_accuracy: 0.4814\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.6545 - binary_accuracy: 0.5995 - val_loss: 0.7111 - val_binary_accuracy: 0.4777\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.6523 - binary_accuracy: 0.5903 - val_loss: 0.7124 - val_binary_accuracy: 0.4917\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.6462 - binary_accuracy: 0.6035 - val_loss: 0.7135 - val_binary_accuracy: 0.4907\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.6545 - binary_accuracy: 0.5963 - val_loss: 0.7121 - val_binary_accuracy: 0.4907\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.6484 - binary_accuracy: 0.5951 - val_loss: 0.7136 - val_binary_accuracy: 0.4870\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.6498 - binary_accuracy: 0.6063 - val_loss: 0.7123 - val_binary_accuracy: 0.4657\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.6508 - binary_accuracy: 0.6043 - val_loss: 0.7140 - val_binary_accuracy: 0.4777\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.6529 - binary_accuracy: 0.6015 - val_loss: 0.7117 - val_binary_accuracy: 0.4712\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.6501 - binary_accuracy: 0.5975 - val_loss: 0.7143 - val_binary_accuracy: 0.4842\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.6499 - binary_accuracy: 0.6031 - val_loss: 0.7115 - val_binary_accuracy: 0.4740\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.6516 - binary_accuracy: 0.5871 - val_loss: 0.7128 - val_binary_accuracy: 0.4768\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.6522 - binary_accuracy: 0.6059 - val_loss: 0.7129 - val_binary_accuracy: 0.4750\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.6502 - binary_accuracy: 0.6051 - val_loss: 0.7107 - val_binary_accuracy: 0.4805\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.6477 - binary_accuracy: 0.6063 - val_loss: 0.7142 - val_binary_accuracy: 0.4768\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.6428 - binary_accuracy: 0.6239 - val_loss: 0.7132 - val_binary_accuracy: 0.4740\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.6476 - binary_accuracy: 0.6059 - val_loss: 0.7182 - val_binary_accuracy: 0.4842\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.6466 - binary_accuracy: 0.6211 - val_loss: 0.7154 - val_binary_accuracy: 0.4675\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.6515 - binary_accuracy: 0.6099 - val_loss: 0.7164 - val_binary_accuracy: 0.4814\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.6504 - binary_accuracy: 0.6075 - val_loss: 0.7173 - val_binary_accuracy: 0.4750\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.6479 - binary_accuracy: 0.6199 - val_loss: 0.7150 - val_binary_accuracy: 0.4703\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.6454 - binary_accuracy: 0.6199 - val_loss: 0.7180 - val_binary_accuracy: 0.4777\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.6461 - binary_accuracy: 0.6063 - val_loss: 0.7167 - val_binary_accuracy: 0.4861\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.6440 - binary_accuracy: 0.6123 - val_loss: 0.7185 - val_binary_accuracy: 0.4740\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.6443 - binary_accuracy: 0.6071 - val_loss: 0.7179 - val_binary_accuracy: 0.4768\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.6426 - binary_accuracy: 0.6219 - val_loss: 0.7214 - val_binary_accuracy: 0.4777\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.6504 - binary_accuracy: 0.6127 - val_loss: 0.7191 - val_binary_accuracy: 0.4694\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.6473 - binary_accuracy: 0.6151 - val_loss: 0.7246 - val_binary_accuracy: 0.4824\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.6456 - binary_accuracy: 0.6179 - val_loss: 0.7185 - val_binary_accuracy: 0.4889\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.6444 - binary_accuracy: 0.6131 - val_loss: 0.7220 - val_binary_accuracy: 0.4796\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.6484 - binary_accuracy: 0.6027 - val_loss: 0.7188 - val_binary_accuracy: 0.4768\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.6476 - binary_accuracy: 0.6159 - val_loss: 0.7209 - val_binary_accuracy: 0.4870\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.6428 - binary_accuracy: 0.6147 - val_loss: 0.7210 - val_binary_accuracy: 0.4685\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.6471 - binary_accuracy: 0.6067 - val_loss: 0.7217 - val_binary_accuracy: 0.4768\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.6432 - binary_accuracy: 0.6163 - val_loss: 0.7208 - val_binary_accuracy: 0.4777\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.6433 - binary_accuracy: 0.6223 - val_loss: 0.7220 - val_binary_accuracy: 0.4787\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.6494 - binary_accuracy: 0.6143 - val_loss: 0.7238 - val_binary_accuracy: 0.4824\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.6405 - binary_accuracy: 0.6284 - val_loss: 0.7218 - val_binary_accuracy: 0.4842\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.6481 - binary_accuracy: 0.6051 - val_loss: 0.7183 - val_binary_accuracy: 0.4852\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.6419 - binary_accuracy: 0.6268 - val_loss: 0.7196 - val_binary_accuracy: 0.4824\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.6388 - binary_accuracy: 0.6332 - val_loss: 0.7253 - val_binary_accuracy: 0.4833\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.6415 - binary_accuracy: 0.6191 - val_loss: 0.7238 - val_binary_accuracy: 0.4768\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.6432 - binary_accuracy: 0.6280 - val_loss: 0.7223 - val_binary_accuracy: 0.4805\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.6387 - binary_accuracy: 0.6328 - val_loss: 0.7257 - val_binary_accuracy: 0.4759\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.6414 - binary_accuracy: 0.6252 - val_loss: 0.7251 - val_binary_accuracy: 0.4796\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.6430 - binary_accuracy: 0.6332 - val_loss: 0.7269 - val_binary_accuracy: 0.4759\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.6460 - binary_accuracy: 0.6087 - val_loss: 0.7261 - val_binary_accuracy: 0.4805\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.6387 - binary_accuracy: 0.6235 - val_loss: 0.7218 - val_binary_accuracy: 0.4842\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.6409 - binary_accuracy: 0.6239 - val_loss: 0.7240 - val_binary_accuracy: 0.4777\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.6422 - binary_accuracy: 0.6284 - val_loss: 0.7262 - val_binary_accuracy: 0.4722\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.6435 - binary_accuracy: 0.6308 - val_loss: 0.7264 - val_binary_accuracy: 0.4861\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.6401 - binary_accuracy: 0.6195 - val_loss: 0.7234 - val_binary_accuracy: 0.4777\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.6438 - binary_accuracy: 0.6256 - val_loss: 0.7249 - val_binary_accuracy: 0.4824\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.6457 - binary_accuracy: 0.6059 - val_loss: 0.7239 - val_binary_accuracy: 0.4805\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.6394 - binary_accuracy: 0.6260 - val_loss: 0.7245 - val_binary_accuracy: 0.4805\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.6411 - binary_accuracy: 0.6392 - val_loss: 0.7279 - val_binary_accuracy: 0.4768\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.6385 - binary_accuracy: 0.6231 - val_loss: 0.7283 - val_binary_accuracy: 0.4879\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.6422 - binary_accuracy: 0.6396 - val_loss: 0.7275 - val_binary_accuracy: 0.4768\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.6398 - binary_accuracy: 0.6187 - val_loss: 0.7286 - val_binary_accuracy: 0.4722\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.6416 - binary_accuracy: 0.6344 - val_loss: 0.7281 - val_binary_accuracy: 0.4814\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.6407 - binary_accuracy: 0.6252 - val_loss: 0.7280 - val_binary_accuracy: 0.4796\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.6440 - binary_accuracy: 0.6276 - val_loss: 0.7258 - val_binary_accuracy: 0.4796\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.6296 - binary_accuracy: 0.6412 - val_loss: 0.7273 - val_binary_accuracy: 0.4889\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.6336 - binary_accuracy: 0.6308 - val_loss: 0.7303 - val_binary_accuracy: 0.4814\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.6307 - binary_accuracy: 0.6276 - val_loss: 0.7317 - val_binary_accuracy: 0.4870\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.6344 - binary_accuracy: 0.6380 - val_loss: 0.7294 - val_binary_accuracy: 0.4768\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.6329 - binary_accuracy: 0.6452 - val_loss: 0.7335 - val_binary_accuracy: 0.4852\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.6378 - binary_accuracy: 0.6304 - val_loss: 0.7311 - val_binary_accuracy: 0.4842\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.6361 - binary_accuracy: 0.6300 - val_loss: 0.7296 - val_binary_accuracy: 0.4814\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.6388 - binary_accuracy: 0.6348 - val_loss: 0.7317 - val_binary_accuracy: 0.4852\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.6326 - binary_accuracy: 0.6416 - val_loss: 0.7327 - val_binary_accuracy: 0.4861\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.6323 - binary_accuracy: 0.6296 - val_loss: 0.7324 - val_binary_accuracy: 0.4861\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.6303 - binary_accuracy: 0.6424 - val_loss: 0.7343 - val_binary_accuracy: 0.4879\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.6332 - binary_accuracy: 0.6408 - val_loss: 0.7383 - val_binary_accuracy: 0.4796\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.6331 - binary_accuracy: 0.6324 - val_loss: 0.7383 - val_binary_accuracy: 0.4722\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.6368 - binary_accuracy: 0.6396 - val_loss: 0.7361 - val_binary_accuracy: 0.4852\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.6311 - binary_accuracy: 0.6384 - val_loss: 0.7357 - val_binary_accuracy: 0.4833\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.6365 - binary_accuracy: 0.6380 - val_loss: 0.7311 - val_binary_accuracy: 0.4824\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.6357 - binary_accuracy: 0.6292 - val_loss: 0.7310 - val_binary_accuracy: 0.5009\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.6331 - binary_accuracy: 0.6300 - val_loss: 0.7323 - val_binary_accuracy: 0.4805\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.6331 - binary_accuracy: 0.6324 - val_loss: 0.7320 - val_binary_accuracy: 0.4917\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.6313 - binary_accuracy: 0.6420 - val_loss: 0.7404 - val_binary_accuracy: 0.4777\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.6322 - binary_accuracy: 0.6380 - val_loss: 0.7375 - val_binary_accuracy: 0.4777\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.6312 - binary_accuracy: 0.6448 - val_loss: 0.7329 - val_binary_accuracy: 0.4926\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.6322 - binary_accuracy: 0.6400 - val_loss: 0.7427 - val_binary_accuracy: 0.4898\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.6386 - binary_accuracy: 0.6388 - val_loss: 0.7387 - val_binary_accuracy: 0.4805\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.6380 - binary_accuracy: 0.6155 - val_loss: 0.7338 - val_binary_accuracy: 0.4787\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.6314 - binary_accuracy: 0.6300 - val_loss: 0.7396 - val_binary_accuracy: 0.4796\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.6328 - binary_accuracy: 0.6312 - val_loss: 0.7397 - val_binary_accuracy: 0.4814\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.6304 - binary_accuracy: 0.6380 - val_loss: 0.7340 - val_binary_accuracy: 0.4981\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.6374 - binary_accuracy: 0.6400 - val_loss: 0.7407 - val_binary_accuracy: 0.4824\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.6281 - binary_accuracy: 0.6440 - val_loss: 0.7378 - val_binary_accuracy: 0.4991\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.6266 - binary_accuracy: 0.6440 - val_loss: 0.7366 - val_binary_accuracy: 0.4926\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.6318 - binary_accuracy: 0.6424 - val_loss: 0.7422 - val_binary_accuracy: 0.4777\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.6291 - binary_accuracy: 0.6488 - val_loss: 0.7476 - val_binary_accuracy: 0.4777\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.6240 - binary_accuracy: 0.6456 - val_loss: 0.7440 - val_binary_accuracy: 0.4907\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.6246 - binary_accuracy: 0.6488 - val_loss: 0.7406 - val_binary_accuracy: 0.4889\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.6238 - binary_accuracy: 0.6580 - val_loss: 0.7427 - val_binary_accuracy: 0.4898\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.6335 - binary_accuracy: 0.6412 - val_loss: 0.7368 - val_binary_accuracy: 0.4879\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.6235 - binary_accuracy: 0.6436 - val_loss: 0.7373 - val_binary_accuracy: 0.4935\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.6275 - binary_accuracy: 0.6416 - val_loss: 0.7421 - val_binary_accuracy: 0.4926\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.6232 - binary_accuracy: 0.6472 - val_loss: 0.7431 - val_binary_accuracy: 0.4824\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.6198 - binary_accuracy: 0.6564 - val_loss: 0.7407 - val_binary_accuracy: 0.4833\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.6254 - binary_accuracy: 0.6456 - val_loss: 0.7436 - val_binary_accuracy: 0.4907\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.6296 - binary_accuracy: 0.6412 - val_loss: 0.7421 - val_binary_accuracy: 0.4889\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.6227 - binary_accuracy: 0.6552 - val_loss: 0.7466 - val_binary_accuracy: 0.4768\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.6219 - binary_accuracy: 0.6608 - val_loss: 0.7493 - val_binary_accuracy: 0.4963\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.6247 - binary_accuracy: 0.6508 - val_loss: 0.7454 - val_binary_accuracy: 0.4981\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.6291 - binary_accuracy: 0.6460 - val_loss: 0.7485 - val_binary_accuracy: 0.4889\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.6296 - binary_accuracy: 0.6420 - val_loss: 0.7498 - val_binary_accuracy: 0.4898\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.6309 - binary_accuracy: 0.6400 - val_loss: 0.7391 - val_binary_accuracy: 0.4814\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.6264 - binary_accuracy: 0.6540 - val_loss: 0.7482 - val_binary_accuracy: 0.4870\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.6207 - binary_accuracy: 0.6520 - val_loss: 0.7353 - val_binary_accuracy: 0.5046\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.6197 - binary_accuracy: 0.6576 - val_loss: 0.7493 - val_binary_accuracy: 0.4879\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.6138 - binary_accuracy: 0.6580 - val_loss: 0.7450 - val_binary_accuracy: 0.4963\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.6294 - binary_accuracy: 0.6420 - val_loss: 0.7409 - val_binary_accuracy: 0.4907\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.6154 - binary_accuracy: 0.6632 - val_loss: 0.7453 - val_binary_accuracy: 0.4842\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.6189 - binary_accuracy: 0.6628 - val_loss: 0.7453 - val_binary_accuracy: 0.4954\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.6195 - binary_accuracy: 0.6476 - val_loss: 0.7379 - val_binary_accuracy: 0.5019\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.6217 - binary_accuracy: 0.6556 - val_loss: 0.7520 - val_binary_accuracy: 0.4991\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.6243 - binary_accuracy: 0.6448 - val_loss: 0.7579 - val_binary_accuracy: 0.4805\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.6271 - binary_accuracy: 0.6516 - val_loss: 0.7495 - val_binary_accuracy: 0.4870\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.6234 - binary_accuracy: 0.6440 - val_loss: 0.7443 - val_binary_accuracy: 0.5000\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.6197 - binary_accuracy: 0.6504 - val_loss: 0.7430 - val_binary_accuracy: 0.4889\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.6237 - binary_accuracy: 0.6544 - val_loss: 0.7323 - val_binary_accuracy: 0.4991\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.6159 - binary_accuracy: 0.6556 - val_loss: 0.7429 - val_binary_accuracy: 0.4963\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.6200 - binary_accuracy: 0.6532 - val_loss: 0.7515 - val_binary_accuracy: 0.4926\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.6217 - binary_accuracy: 0.6552 - val_loss: 0.7399 - val_binary_accuracy: 0.4852\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.6234 - binary_accuracy: 0.6492 - val_loss: 0.7352 - val_binary_accuracy: 0.5009\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.6182 - binary_accuracy: 0.6552 - val_loss: 0.7532 - val_binary_accuracy: 0.4833\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.6238 - binary_accuracy: 0.6508 - val_loss: 0.7441 - val_binary_accuracy: 0.4954\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.6175 - binary_accuracy: 0.6628 - val_loss: 0.7523 - val_binary_accuracy: 0.4814\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.6168 - binary_accuracy: 0.6656 - val_loss: 0.7401 - val_binary_accuracy: 0.4926\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.6177 - binary_accuracy: 0.6584 - val_loss: 0.7402 - val_binary_accuracy: 0.4972\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.6167 - binary_accuracy: 0.6548 - val_loss: 0.7381 - val_binary_accuracy: 0.5046\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.6125 - binary_accuracy: 0.6780 - val_loss: 0.7540 - val_binary_accuracy: 0.4787\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.6115 - binary_accuracy: 0.6572 - val_loss: 0.7400 - val_binary_accuracy: 0.4981\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.6135 - binary_accuracy: 0.6632 - val_loss: 0.7561 - val_binary_accuracy: 0.4852\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.6146 - binary_accuracy: 0.6652 - val_loss: 0.7479 - val_binary_accuracy: 0.4917\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.6114 - binary_accuracy: 0.6628 - val_loss: 0.7453 - val_binary_accuracy: 0.4879\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.6153 - binary_accuracy: 0.6632 - val_loss: 0.7572 - val_binary_accuracy: 0.4852\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.6121 - binary_accuracy: 0.6716 - val_loss: 0.7513 - val_binary_accuracy: 0.4935\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.6171 - binary_accuracy: 0.6576 - val_loss: 0.7419 - val_binary_accuracy: 0.5065\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.6158 - binary_accuracy: 0.6572 - val_loss: 0.7620 - val_binary_accuracy: 0.4852\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.6109 - binary_accuracy: 0.6592 - val_loss: 0.7535 - val_binary_accuracy: 0.4907\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.6185 - binary_accuracy: 0.6608 - val_loss: 0.7444 - val_binary_accuracy: 0.5037\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.6126 - binary_accuracy: 0.6592 - val_loss: 0.7635 - val_binary_accuracy: 0.4917\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.6157 - binary_accuracy: 0.6616 - val_loss: 0.7440 - val_binary_accuracy: 0.4935\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.6129 - binary_accuracy: 0.6632 - val_loss: 0.7471 - val_binary_accuracy: 0.5037\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.6235 - binary_accuracy: 0.6468 - val_loss: 0.7404 - val_binary_accuracy: 0.5269\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.6087 - binary_accuracy: 0.6692 - val_loss: 0.7594 - val_binary_accuracy: 0.5037\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.6148 - binary_accuracy: 0.6644 - val_loss: 0.7498 - val_binary_accuracy: 0.5019\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.6098 - binary_accuracy: 0.6668 - val_loss: 0.7378 - val_binary_accuracy: 0.5083\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.6093 - binary_accuracy: 0.6680 - val_loss: 0.7494 - val_binary_accuracy: 0.4842\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.6186 - binary_accuracy: 0.6544 - val_loss: 0.7485 - val_binary_accuracy: 0.5028\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.6125 - binary_accuracy: 0.6656 - val_loss: 0.7710 - val_binary_accuracy: 0.4814\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.6135 - binary_accuracy: 0.6708 - val_loss: 0.7377 - val_binary_accuracy: 0.5065\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.6101 - binary_accuracy: 0.6608 - val_loss: 0.7502 - val_binary_accuracy: 0.5000\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.6128 - binary_accuracy: 0.6648 - val_loss: 0.7659 - val_binary_accuracy: 0.4777\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.6149 - binary_accuracy: 0.6644 - val_loss: 0.7539 - val_binary_accuracy: 0.5074\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.6062 - binary_accuracy: 0.6716 - val_loss: 0.7622 - val_binary_accuracy: 0.4917\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.6143 - binary_accuracy: 0.6644 - val_loss: 0.7484 - val_binary_accuracy: 0.5102\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.6089 - binary_accuracy: 0.6684 - val_loss: 0.7667 - val_binary_accuracy: 0.4833\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.6106 - binary_accuracy: 0.6656 - val_loss: 0.7396 - val_binary_accuracy: 0.5111\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.6063 - binary_accuracy: 0.6760 - val_loss: 0.7764 - val_binary_accuracy: 0.4814\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.6121 - binary_accuracy: 0.6696 - val_loss: 0.7447 - val_binary_accuracy: 0.5250\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.6116 - binary_accuracy: 0.6656 - val_loss: 0.7628 - val_binary_accuracy: 0.4935\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.6089 - binary_accuracy: 0.6620 - val_loss: 0.7381 - val_binary_accuracy: 0.5204\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.6081 - binary_accuracy: 0.6716 - val_loss: 0.7503 - val_binary_accuracy: 0.5009\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.6049 - binary_accuracy: 0.6660 - val_loss: 0.7684 - val_binary_accuracy: 0.4824\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.6111 - binary_accuracy: 0.6660 - val_loss: 0.7464 - val_binary_accuracy: 0.5102\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.6071 - binary_accuracy: 0.6712 - val_loss: 0.7718 - val_binary_accuracy: 0.4972\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.6096 - binary_accuracy: 0.6668 - val_loss: 0.7569 - val_binary_accuracy: 0.4991\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.6054 - binary_accuracy: 0.6736 - val_loss: 0.7587 - val_binary_accuracy: 0.5037\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.6090 - binary_accuracy: 0.6660 - val_loss: 0.7584 - val_binary_accuracy: 0.4889\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.6067 - binary_accuracy: 0.6636 - val_loss: 0.7707 - val_binary_accuracy: 0.4879\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.6073 - binary_accuracy: 0.6684 - val_loss: 0.7554 - val_binary_accuracy: 0.5102\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.6052 - binary_accuracy: 0.6688 - val_loss: 0.7410 - val_binary_accuracy: 0.5427\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.6157 - binary_accuracy: 0.6664 - val_loss: 0.7814 - val_binary_accuracy: 0.4833\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.6154 - binary_accuracy: 0.6536 - val_loss: 0.7449 - val_binary_accuracy: 0.5019\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.6118 - binary_accuracy: 0.6688 - val_loss: 0.7561 - val_binary_accuracy: 0.5056\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.6048 - binary_accuracy: 0.6700 - val_loss: 0.7605 - val_binary_accuracy: 0.5065\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.6051 - binary_accuracy: 0.6676 - val_loss: 0.7556 - val_binary_accuracy: 0.5121\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.6108 - binary_accuracy: 0.6736 - val_loss: 0.7767 - val_binary_accuracy: 0.4879\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.6101 - binary_accuracy: 0.6716 - val_loss: 0.7717 - val_binary_accuracy: 0.4954\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.6047 - binary_accuracy: 0.6704 - val_loss: 0.7457 - val_binary_accuracy: 0.5204\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.6038 - binary_accuracy: 0.6760 - val_loss: 0.7626 - val_binary_accuracy: 0.5074\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.6085 - binary_accuracy: 0.6664 - val_loss: 0.7624 - val_binary_accuracy: 0.5028\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.6029 - binary_accuracy: 0.6752 - val_loss: 0.7611 - val_binary_accuracy: 0.4870\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.6010 - binary_accuracy: 0.6696 - val_loss: 0.7719 - val_binary_accuracy: 0.4870\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.6071 - binary_accuracy: 0.6680 - val_loss: 0.7744 - val_binary_accuracy: 0.4917\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.6085 - binary_accuracy: 0.6740 - val_loss: 0.7486 - val_binary_accuracy: 0.5315\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.6051 - binary_accuracy: 0.6688 - val_loss: 0.7727 - val_binary_accuracy: 0.4944\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.6101 - binary_accuracy: 0.6624 - val_loss: 0.7411 - val_binary_accuracy: 0.5158\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.6070 - binary_accuracy: 0.6676 - val_loss: 0.7614 - val_binary_accuracy: 0.4954\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.6043 - binary_accuracy: 0.6704 - val_loss: 0.7576 - val_binary_accuracy: 0.5056\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.6016 - binary_accuracy: 0.6760 - val_loss: 0.7540 - val_binary_accuracy: 0.5019\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.5993 - binary_accuracy: 0.6700 - val_loss: 0.7567 - val_binary_accuracy: 0.5028\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.6030 - binary_accuracy: 0.6856 - val_loss: 0.7661 - val_binary_accuracy: 0.5093\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.6033 - binary_accuracy: 0.6720 - val_loss: 0.7593 - val_binary_accuracy: 0.5046\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.6065 - binary_accuracy: 0.6640 - val_loss: 0.7635 - val_binary_accuracy: 0.5037\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.6065 - binary_accuracy: 0.6712 - val_loss: 0.7475 - val_binary_accuracy: 0.5148\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.5976 - binary_accuracy: 0.6780 - val_loss: 0.7754 - val_binary_accuracy: 0.5065\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.6013 - binary_accuracy: 0.6692 - val_loss: 0.7397 - val_binary_accuracy: 0.5464\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.6028 - binary_accuracy: 0.6728 - val_loss: 0.7805 - val_binary_accuracy: 0.5000\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.6031 - binary_accuracy: 0.6748 - val_loss: 0.7466 - val_binary_accuracy: 0.5213\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.6054 - binary_accuracy: 0.6736 - val_loss: 0.7770 - val_binary_accuracy: 0.5102\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.6046 - binary_accuracy: 0.6740 - val_loss: 0.7477 - val_binary_accuracy: 0.5353\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.6088 - binary_accuracy: 0.6692 - val_loss: 0.7927 - val_binary_accuracy: 0.4759\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.6036 - binary_accuracy: 0.6648 - val_loss: 0.7436 - val_binary_accuracy: 0.5297\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.6027 - binary_accuracy: 0.6748 - val_loss: 0.7845 - val_binary_accuracy: 0.5028\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.6029 - binary_accuracy: 0.6736 - val_loss: 0.7645 - val_binary_accuracy: 0.5121\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.6073 - binary_accuracy: 0.6712 - val_loss: 0.7616 - val_binary_accuracy: 0.5102\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.6043 - binary_accuracy: 0.6784 - val_loss: 0.7678 - val_binary_accuracy: 0.4963\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.6040 - binary_accuracy: 0.6728 - val_loss: 0.7783 - val_binary_accuracy: 0.4963\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.6017 - binary_accuracy: 0.6740 - val_loss: 0.7579 - val_binary_accuracy: 0.5083\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.6017 - binary_accuracy: 0.6800 - val_loss: 0.7916 - val_binary_accuracy: 0.4963\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.6040 - binary_accuracy: 0.6768 - val_loss: 0.7521 - val_binary_accuracy: 0.5167\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.6001 - binary_accuracy: 0.6780 - val_loss: 0.7783 - val_binary_accuracy: 0.5130\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.5967 - binary_accuracy: 0.6784 - val_loss: 0.7907 - val_binary_accuracy: 0.4917\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.5999 - binary_accuracy: 0.6668 - val_loss: 0.7617 - val_binary_accuracy: 0.5139\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.5946 - binary_accuracy: 0.6828 - val_loss: 0.7707 - val_binary_accuracy: 0.5111\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.5936 - binary_accuracy: 0.6796 - val_loss: 0.7711 - val_binary_accuracy: 0.5204\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.6011 - binary_accuracy: 0.6712 - val_loss: 0.7637 - val_binary_accuracy: 0.5028\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.6043 - binary_accuracy: 0.6668 - val_loss: 0.7616 - val_binary_accuracy: 0.5130\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.6037 - binary_accuracy: 0.6760 - val_loss: 0.7629 - val_binary_accuracy: 0.5093\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.5973 - binary_accuracy: 0.6816 - val_loss: 0.7758 - val_binary_accuracy: 0.5037\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.5984 - binary_accuracy: 0.6740 - val_loss: 0.7677 - val_binary_accuracy: 0.5037\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.5966 - binary_accuracy: 0.6796 - val_loss: 0.7680 - val_binary_accuracy: 0.5056\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.6040 - binary_accuracy: 0.6748 - val_loss: 0.7749 - val_binary_accuracy: 0.5046\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.6007 - binary_accuracy: 0.6764 - val_loss: 0.7616 - val_binary_accuracy: 0.5028\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.5995 - binary_accuracy: 0.6824 - val_loss: 0.7782 - val_binary_accuracy: 0.5028\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.5986 - binary_accuracy: 0.6772 - val_loss: 0.7632 - val_binary_accuracy: 0.5121\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.5988 - binary_accuracy: 0.6776 - val_loss: 0.7660 - val_binary_accuracy: 0.5093\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.5983 - binary_accuracy: 0.6776 - val_loss: 0.7615 - val_binary_accuracy: 0.5111\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.6011 - binary_accuracy: 0.6764 - val_loss: 0.7836 - val_binary_accuracy: 0.5046\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.6040 - binary_accuracy: 0.6736 - val_loss: 0.7527 - val_binary_accuracy: 0.5083\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.6019 - binary_accuracy: 0.6760 - val_loss: 0.7777 - val_binary_accuracy: 0.5102\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.5960 - binary_accuracy: 0.6724 - val_loss: 0.7602 - val_binary_accuracy: 0.5195\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.5978 - binary_accuracy: 0.6808 - val_loss: 0.7869 - val_binary_accuracy: 0.5102\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.6060 - binary_accuracy: 0.6696 - val_loss: 0.7669 - val_binary_accuracy: 0.5241\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.5971 - binary_accuracy: 0.6736 - val_loss: 0.7693 - val_binary_accuracy: 0.5009\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.5989 - binary_accuracy: 0.6752 - val_loss: 0.7825 - val_binary_accuracy: 0.5037\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.5966 - binary_accuracy: 0.6788 - val_loss: 0.7482 - val_binary_accuracy: 0.5130\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.6034 - binary_accuracy: 0.6764 - val_loss: 0.7720 - val_binary_accuracy: 0.5167\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.6013 - binary_accuracy: 0.6688 - val_loss: 0.7559 - val_binary_accuracy: 0.5232\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.5986 - binary_accuracy: 0.6696 - val_loss: 0.7979 - val_binary_accuracy: 0.4861\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.5949 - binary_accuracy: 0.6772 - val_loss: 0.7472 - val_binary_accuracy: 0.5399\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.5987 - binary_accuracy: 0.6764 - val_loss: 0.7836 - val_binary_accuracy: 0.5009\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.5994 - binary_accuracy: 0.6708 - val_loss: 0.7562 - val_binary_accuracy: 0.5223\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.5990 - binary_accuracy: 0.6720 - val_loss: 0.7979 - val_binary_accuracy: 0.5056\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.6001 - binary_accuracy: 0.6704 - val_loss: 0.7475 - val_binary_accuracy: 0.5074\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.5986 - binary_accuracy: 0.6780 - val_loss: 0.7775 - val_binary_accuracy: 0.5130\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.6026 - binary_accuracy: 0.6792 - val_loss: 0.8014 - val_binary_accuracy: 0.4972\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.6005 - binary_accuracy: 0.6760 - val_loss: 0.7660 - val_binary_accuracy: 0.5083\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.5939 - binary_accuracy: 0.6720 - val_loss: 0.7692 - val_binary_accuracy: 0.5083\n"
     ]
    }
   ],
   "source": [
    "test = make_model(dropout_param=0.5, mid_hl_size=80, no_layers=8, optimizer=\"Adamax\", #RMSProp #0.37\n",
    "                  first_last_hl_size=20, input_activation=\"softmax\").fit(X_train, y_train, validation_data = (X_val, y_val), \n",
    "                                                                         epochs=500, batch_size=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5111039113876771"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test.history['val_binary_accuracy'][-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test.history['binary_accuracy'])\n",
    "plt.plot(test.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28a12a89438>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test.history['loss'])\n",
    "plt.plot(test.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nils\\Anaconda3\\lib\\site-packages\\keras\\activations.py:103: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  ).format(identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 20 samples\n",
      "Epoch 1/30\n",
      "79/79 [==============================] - 1s 13ms/step - loss: 0.6909 - acc: 0.2278 - val_loss: 0.6894 - val_acc: 0.2000\n",
      "Epoch 2/30\n",
      "79/79 [==============================] - 0s 202us/step - loss: 0.6894 - acc: 0.2186 - val_loss: 0.6891 - val_acc: 0.2000\n",
      "Epoch 3/30\n",
      "79/79 [==============================] - 0s 380us/step - loss: 0.6903 - acc: 0.2221 - val_loss: 0.6887 - val_acc: 0.1864\n",
      "Epoch 4/30\n",
      "79/79 [==============================] - 0s 329us/step - loss: 0.6891 - acc: 0.2083 - val_loss: 0.6884 - val_acc: 0.1727\n",
      "Epoch 5/30\n",
      "79/79 [==============================] - 0s 380us/step - loss: 0.6889 - acc: 0.2048 - val_loss: 0.6880 - val_acc: 0.1591\n",
      "Epoch 6/30\n",
      "79/79 [==============================] - 0s 380us/step - loss: 0.6885 - acc: 0.1933 - val_loss: 0.6877 - val_acc: 0.1455\n",
      "Epoch 7/30\n",
      "79/79 [==============================] - 0s 392us/step - loss: 0.6899 - acc: 0.1772 - val_loss: 0.6873 - val_acc: 0.1409\n",
      "Epoch 8/30\n",
      "79/79 [==============================] - 0s 354us/step - loss: 0.6887 - acc: 0.1910 - val_loss: 0.6870 - val_acc: 0.1318\n",
      "Epoch 9/30\n",
      "79/79 [==============================] - 0s 304us/step - loss: 0.6889 - acc: 0.1853 - val_loss: 0.6866 - val_acc: 0.1227\n",
      "Epoch 10/30\n",
      "79/79 [==============================] - 0s 304us/step - loss: 0.6867 - acc: 0.1910 - val_loss: 0.6863 - val_acc: 0.1227\n",
      "Epoch 11/30\n",
      "79/79 [==============================] - 0s 519us/step - loss: 0.6871 - acc: 0.1784 - val_loss: 0.6860 - val_acc: 0.1227\n",
      "Epoch 12/30\n",
      "79/79 [==============================] - 0s 279us/step - loss: 0.6863 - acc: 0.1715 - val_loss: 0.6856 - val_acc: 0.1182\n",
      "Epoch 13/30\n",
      "79/79 [==============================] - 0s 266us/step - loss: 0.6867 - acc: 0.1554 - val_loss: 0.6853 - val_acc: 0.1136\n",
      "Epoch 14/30\n",
      "79/79 [==============================] - 0s 329us/step - loss: 0.6868 - acc: 0.1692 - val_loss: 0.6849 - val_acc: 0.1136\n",
      "Epoch 15/30\n",
      "79/79 [==============================] - 0s 354us/step - loss: 0.6860 - acc: 0.1530 - val_loss: 0.6846 - val_acc: 0.1136\n",
      "Epoch 16/30\n",
      "79/79 [==============================] - 0s 292us/step - loss: 0.6867 - acc: 0.1646 - val_loss: 0.6843 - val_acc: 0.1136\n",
      "Epoch 17/30\n",
      "79/79 [==============================] - 0s 254us/step - loss: 0.6864 - acc: 0.1496 - val_loss: 0.6839 - val_acc: 0.1136\n",
      "Epoch 18/30\n",
      "79/79 [==============================] - 0s 316us/step - loss: 0.6857 - acc: 0.1346 - val_loss: 0.6836 - val_acc: 0.1136\n",
      "Epoch 19/30\n",
      "79/79 [==============================] - 0s 354us/step - loss: 0.6852 - acc: 0.1335 - val_loss: 0.6832 - val_acc: 0.1136\n",
      "Epoch 20/30\n",
      "79/79 [==============================] - 0s 253us/step - loss: 0.6847 - acc: 0.1427 - val_loss: 0.6829 - val_acc: 0.1045\n",
      "Epoch 21/30\n",
      "79/79 [==============================] - 0s 241us/step - loss: 0.6844 - acc: 0.1231 - val_loss: 0.6826 - val_acc: 0.0955\n",
      "Epoch 22/30\n",
      "79/79 [==============================] - 0s 291us/step - loss: 0.6831 - acc: 0.1208 - val_loss: 0.6822 - val_acc: 0.0909\n",
      "Epoch 23/30\n",
      "79/79 [==============================] - 0s 279us/step - loss: 0.6850 - acc: 0.1220 - val_loss: 0.6819 - val_acc: 0.0909\n",
      "Epoch 24/30\n",
      "79/79 [==============================] - 0s 279us/step - loss: 0.6834 - acc: 0.1300 - val_loss: 0.6815 - val_acc: 0.0864\n",
      "Epoch 25/30\n",
      "79/79 [==============================] - 0s 278us/step - loss: 0.6837 - acc: 0.1300 - val_loss: 0.6812 - val_acc: 0.0864\n",
      "Epoch 26/30\n",
      "79/79 [==============================] - 0s 291us/step - loss: 0.6847 - acc: 0.0967 - val_loss: 0.6808 - val_acc: 0.0864\n",
      "Epoch 27/30\n",
      "79/79 [==============================] - 0s 291us/step - loss: 0.6818 - acc: 0.1174 - val_loss: 0.6805 - val_acc: 0.0727\n",
      "Epoch 28/30\n",
      "79/79 [==============================] - 0s 253us/step - loss: 0.6827 - acc: 0.0955 - val_loss: 0.6801 - val_acc: 0.0727\n",
      "Epoch 29/30\n",
      "79/79 [==============================] - 0s 228us/step - loss: 0.6821 - acc: 0.0944 - val_loss: 0.6798 - val_acc: 0.0727\n",
      "Epoch 30/30\n",
      "79/79 [==============================] - 0s 279us/step - loss: 0.6809 - acc: 0.1013 - val_loss: 0.6795 - val_acc: 0.0727\n",
      "20/20 [==============================] - 0s 350us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Optimizer\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.6, nesterov=True)\n",
    "\n",
    "#Input Layer\n",
    "model.add(Dense(nb_classes, input_shape=(dims,), activation=\"softmax\"))#LeakyReLU(alpha=0.3)\n",
    "\n",
    "#Hidden Layers\n",
    "model.add(Dense(300, activation=LeakyReLU(alpha=0.3), use_bias=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(500, activation=\"relu\", use_bias=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(300, activation=\"relu\", use_bias=True))\n",
    "#model.add(Activation('softplus'))\n",
    "\n",
    "#Output Layer\n",
    "model.add(Dense(nb_classes, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=30, \n",
    "          batch_size=128, verbose=True)\n",
    "\n",
    "score = model.evaluate(X_val, y_val,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 1.0000000e+00, 1.2261952e-27, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 6.2738419e-01, 1.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = model.predict(X[0].reshape(1,90))\n",
    "E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
